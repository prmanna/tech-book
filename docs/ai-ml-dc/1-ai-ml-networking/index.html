<!doctype html><html lang=en-us dir=ltr><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="
  Intro
  #


  AI/ML Networking Part I: RDMA Basics
  #

TBD

  AI/ML Networking: Part-II: Introduction of Deep Neural Networks
  #

Machine Learning (ML) is a subset of Artificial Intelligence (AI). ML is based on algorithms that allow learning, predicting, and making decisions based on data rather than pre-programmed tasks. ML leverages Deep Neural Networks (DNNs), which have multiple layers, each consisting of neurons that process information from sub-layers as part of the training process. Large Language Models (LLMs), such as OpenAI’s GPT (Generative Pre-trained Transformers), utilize ML and Deep Neural Networks."><meta name=theme-color media="(prefers-color-scheme: light)" content="#ffffff"><meta name=theme-color media="(prefers-color-scheme: dark)" content="#343a40"><meta name=color-scheme content="light dark"><meta property="og:url" content="https://prasenjitmanna.com/tech-book/docs/ai-ml-dc/1-ai-ml-networking/"><meta property="og:site_name" content="Technical Book"><meta property="og:title" content="AI/ML Networking"><meta property="og:description" content=" Intro # AI/ML Networking Part I: RDMA Basics # TBD
AI/ML Networking: Part-II: Introduction of Deep Neural Networks # Machine Learning (ML) is a subset of Artificial Intelligence (AI). ML is based on algorithms that allow learning, predicting, and making decisions based on data rather than pre-programmed tasks. ML leverages Deep Neural Networks (DNNs), which have multiple layers, each consisting of neurons that process information from sub-layers as part of the training process. Large Language Models (LLMs), such as OpenAI’s GPT (Generative Pre-trained Transformers), utilize ML and Deep Neural Networks."><meta property="og:locale" content="en_us"><meta property="og:type" content="article"><meta property="article:section" content="docs"><meta property="article:modified_time" content="2025-05-08T22:54:13+05:30"><title>AI/ML Networking | Technical Book</title>
<link rel=manifest href=/tech-book/manifest.json><link rel=icon href=/tech-book/favicon.png><link rel=canonical href=https://prasenjitmanna.com/tech-book/docs/ai-ml-dc/1-ai-ml-networking/><link rel=stylesheet href=/tech-book/book.min.a61cdb2979f3c2bece54ef69131fba427dd57d55c232d3bb5fdb62ac41aa8354.css integrity="sha256-phzbKXnzwr7OVO9pEx+6Qn3VfVXCMtO7X9tirEGqg1Q=" crossorigin=anonymous><script defer src=/tech-book/fuse.min.js></script><script defer src=/tech-book/en.search.min.704591c29afe892fab060def68d7f56e246c02dfd61187df42d0e4887cedb346.js integrity="sha256-cEWRwpr+iS+rBg3vaNf1biRsAt/WEYffQtDkiHzts0Y=" crossorigin=anonymous></script></head><body dir=ltr><input type=checkbox class="hidden toggle" id=menu-control>
<input type=checkbox class="hidden toggle" id=toc-control><main class="container flex"><aside class=book-menu><div class=book-menu-content><nav><h2 class=book-brand><a class="flex align-center" href=/tech-book/><img src=/tech-book/logo.png alt=Logo><span>Technical Book</span></a></h2><div class="book-search hidden"><input type=text id=book-search-input placeholder=Search aria-label=Search maxlength=64 data-hotkeys=s/><div class="book-search-spinner hidden"></div><ul id=book-search-results></ul></div><script>document.querySelector(".book-search").classList.remove("hidden")</script><ul><li><input type=checkbox id=section-99f552133860bc21797a47fe73e93434 class=toggle>
<label for=section-99f552133860bc21797a47fe73e93434 class="flex justify-between"><a href=/tech-book/docs/5g/>5G</a></label><ul><li><input type=checkbox id=section-dfc790b73acb0410a0114547cbf5af32 class=toggle>
<label for=section-dfc790b73acb0410a0114547cbf5af32 class="flex justify-between"><a href=/tech-book/docs/5g/5g-intro/>An Overview of 5G Networking</a></label></li></ul></li><li><input type=checkbox id=section-7c4a3b16aeeb5b7194b232c1eef2f4fb class=toggle>
<label for=section-7c4a3b16aeeb5b7194b232c1eef2f4fb class="flex justify-between"><a href=/tech-book/docs/algorithms/>Algorithms</a></label><ul><li><input type=checkbox id=section-8956d82fbe6869140758f7e8679174bc class=toggle>
<label for=section-8956d82fbe6869140758f7e8679174bc class="flex justify-between"><a href=/tech-book/docs/algorithms/breadth-first-search/>Breadth First Search</a></label></li><li><input type=checkbox id=section-5a049cfad1740f3fd30565524385fa57 class=toggle>
<label for=section-5a049cfad1740f3fd30565524385fa57 class="flex justify-between"><a href=/tech-book/docs/algorithms/depth-first-search/>Depth First Search</a></label></li><li><input type=checkbox id=section-ebc049f26d82165be8c6f1f9e504e799 class=toggle>
<label for=section-ebc049f26d82165be8c6f1f9e504e799 class="flex justify-between"><a href=/tech-book/docs/algorithms/easy/>Easy Complexity</a></label></li><li><input type=checkbox id=section-1071946392bd1f431993e950147fa054 class=toggle>
<label for=section-1071946392bd1f431993e950147fa054 class="flex justify-between"><a href=/tech-book/docs/algorithms/priority-queue-and-heap/>Priority Queue and Heap</a></label></li><li><input type=checkbox id=section-08afbeb294c43ca4908c1c89a4be9d0a class=toggle>
<label for=section-08afbeb294c43ca4908c1c89a4be9d0a class="flex justify-between"><a href=/tech-book/docs/algorithms/two-pointers/>Two Pointers & Sliding Window</a></label></li><li><input type=checkbox id=section-ef36c7c4f7e0dec6525068c3c409100c class=toggle>
<label for=section-ef36c7c4f7e0dec6525068c3c409100c class="flex justify-between"><a href=/tech-book/docs/algorithms/medium/>Medium Complexity</a></label></li></ul></li><li><input type=checkbox id=section-8c7c5c4a8382299873178820b1d91be1 class=toggle checked>
<label for=section-8c7c5c4a8382299873178820b1d91be1 class="flex justify-between"><a href=/tech-book/docs/ai-ml-dc/>Data Center Networking for AI Clusters</a></label><ul><li><input type=checkbox id=section-433ccede4154db01f6c601940d2949e0 class=toggle checked>
<label for=section-433ccede4154db01f6c601940d2949e0 class="flex justify-between"><a href=/tech-book/docs/ai-ml-dc/1-ai-ml-networking/ class=active>AI/ML Networking</a></label></li><li><input type=checkbox id=section-65f71f2455a94ea3d1143666d556b0ed class=toggle>
<label for=section-65f71f2455a94ea3d1143666d556b0ed class="flex justify-between"><a href=/tech-book/docs/ai-ml-dc/2-ai-deep-learning-basics/>Deep Learning Basics | Artificial Neuron</a></label></li><li><input type=checkbox id=section-af7b72510cdccfb9feb048bbf70c6f27 class=toggle>
<label for=section-af7b72510cdccfb9feb048bbf70c6f27 class="flex justify-between"><a href=/tech-book/docs/ai-ml-dc/2-1-large-language-models/>Large Language Models (LLM)</a></label></li><li><input type=checkbox id=section-b3eb6a6d3a1b87cba26dcfbb99658303 class=toggle>
<label for=section-b3eb6a6d3a1b87cba26dcfbb99658303 class="flex justify-between"><a href=/tech-book/docs/ai-ml-dc/2-2-parallelism-strategies-in-deep-learning/>Parallelism Strategies in Deep Learning</a></label></li><li><input type=checkbox id=section-f11d3aa2e337730e1e3345f8530fe134 class=toggle>
<label for=section-f11d3aa2e337730e1e3345f8530fe134 class="flex justify-between"><a href=/tech-book/docs/ai-ml-dc/3-challenges-in-ai-fabric/>Challenges in AI Fabric Design</a></label></li><li><input type=checkbox id=section-e28420ec7507646128f3695b6f9badbb class=toggle>
<label for=section-e28420ec7507646128f3695b6f9badbb class="flex justify-between"><a href=/tech-book/docs/ai-ml-dc/4-congestion-avoidance-in-ai-fabric/>Congestion Avoidance in AI Fabric</a></label></li><li><input type=checkbox id=section-67bb7cbb1dd95e59f8515201219c090f class=toggle>
<label for=section-67bb7cbb1dd95e59f8515201219c090f class="flex justify-between"><a href=/tech-book/docs/ai-ml-dc/5-load-balancing-in-ai-fabric/>Load Balancing in AI Fabric</a></label></li><li><input type=checkbox id=section-5f3e07f6cf7921e5291ff7894e06b19b class=toggle>
<label for=section-5f3e07f6cf7921e5291ff7894e06b19b class="flex justify-between"><a href=/tech-book/docs/ai-ml-dc/6-backend-network-topologies-for-ai-fabric/>Backend Network Topologies for AI Fabrics</a></label></li><li><input type=checkbox id=section-e19a1e9030cc104536fa46dd0bdb082c class=toggle>
<label for=section-e19a1e9030cc104536fa46dd0bdb082c class="flex justify-between"><a href=/tech-book/docs/ai-ml-dc/7-backend-network-in-gpu-fabric/>Backend Network/Rail Designs</a></label></li></ul></li><li><input type=checkbox id=section-3272b2d28b2b247027bf478619ca416f class=toggle>
<label for=section-3272b2d28b2b247027bf478619ca416f class="flex justify-between"><a href=/tech-book/docs/data-center/>Data Center Tips</a></label><ul><li><input type=checkbox id=section-984f932c7aba4f0a1841e8413165c947 class=toggle>
<label for=section-984f932c7aba4f0a1841e8413165c947 class="flex justify-between"><a href=/tech-book/docs/data-center/data-center-ethernet/>Data Center Ethernet</a></label></li><li><input type=checkbox id=section-bc5ac88940153a700e63e3be886c63cc class=toggle>
<label for=section-bc5ac88940153a700e63e3be886c63cc class="flex justify-between"><a href=/tech-book/docs/data-center/data-center-technologies/>Data Center Technologies</a></label></li><li><input type=checkbox id=section-86fde1ddf43700ef8191e11c59a82cf1 class=toggle>
<label for=section-86fde1ddf43700ef8191e11c59a82cf1 class="flex justify-between"><a href=/tech-book/docs/data-center/data-center-network-virtualization/>Network Virtualization in Cloud Data Centers</a></label></li></ul></li><li><input type=checkbox id=section-ddf784688e0c6d5abb681d2c57851559 class=toggle>
<label for=section-ddf784688e0c6d5abb681d2c57851559 class="flex justify-between"><a href=/tech-book/docs/manageability/>Manageability</a></label><ul><li><input type=checkbox id=section-33ac730897af6feca81c1fdb7869c57e class=toggle>
<label for=section-33ac730897af6feca81c1fdb7869c57e class="flex justify-between"><a href=/tech-book/docs/manageability/why-grpc-on-http2/>gRPC on HTTP/2</a></label></li></ul></li><li><input type=checkbox id=section-c14ae944424668ef125e10cd791a3d3d class=toggle>
<label for=section-c14ae944424668ef125e10cd791a3d3d class="flex justify-between"><a href=/tech-book/docs/networking-tips/>Networking Tips</a></label><ul><li><input type=checkbox id=section-78fdf21c03c55935d3146441b06faf3e class=toggle>
<label for=section-78fdf21c03c55935d3146441b06faf3e class="flex justify-between"><a href=/tech-book/docs/networking-tips/dns/>DNS Overview</a></label></li><li><input type=checkbox id=section-bbcb027a658dc7a2333d59078ee507f9 class=toggle>
<label for=section-bbcb027a658dc7a2333d59078ee507f9 class="flex justify-between"><a href=/tech-book/docs/networking-tips/ecmp/>ECMP Load Balancing</a></label></li><li><input type=checkbox id=section-3b39b86f18b3451e5b8a1b81c369549c class=toggle>
<label for=section-3b39b86f18b3451e5b8a1b81c369549c class="flex justify-between"><a href=/tech-book/docs/networking-tips/ip-fragmentation/>IP Fragmentation - IPv4 & IPv6</a></label></li><li><input type=checkbox id=section-c6d06c54cc91b0bc3f948d33b437fa8b class=toggle>
<label for=section-c6d06c54cc91b0bc3f948d33b437fa8b class="flex justify-between"><a href=/tech-book/docs/networking-tips/ip-tos-dscp/>IP Precedence And TOS | DSCP</a></label></li><li><input type=checkbox id=section-5f3260c76dd37177e3f89057bfe520ae class=toggle>
<label for=section-5f3260c76dd37177e3f89057bfe520ae class="flex justify-between"><a href=/tech-book/docs/networking-tips/traceroute/>Linux traceroute tool</a></label></li><li><input type=checkbox id=section-a26cc3fafb36cbc55527adf39ec83849 class=toggle>
<label for=section-a26cc3fafb36cbc55527adf39ec83849 class="flex justify-between"><a href=/tech-book/docs/networking-tips/mlag/>Multi Chassis Link Aggregation Basics</a></label></li><li><input type=checkbox id=section-36409a0abcb2d4d4baf2e0b682d1a5dd class=toggle>
<label for=section-36409a0abcb2d4d4baf2e0b682d1a5dd class="flex justify-between"><a href=/tech-book/docs/networking-tips/qos/>QoS</a></label></li><li><input type=checkbox id=section-db41e3547d316b01acf9a0ce9c04ef34 class=toggle>
<label for=section-db41e3547d316b01acf9a0ce9c04ef34 class="flex justify-between"><a href=/tech-book/docs/networking-tips/spine-leaf-arch/>Spine-leaf Architecture Basics</a></label></li><li><input type=checkbox id=section-0eb0d409074a76b8cb02624655e2434d class=toggle>
<label for=section-0eb0d409074a76b8cb02624655e2434d class="flex justify-between"><a href=/tech-book/docs/networking-tips/tcp-congestion/>TCP Congestion Control</a></label></li><li><input type=checkbox id=section-3d1710947b3c5be1a1cc33d88fcc6f54 class=toggle>
<label for=section-3d1710947b3c5be1a1cc33d88fcc6f54 class="flex justify-between"><a href=/tech-book/docs/networking-tips/tcp-data-transfer/>TCP Data Transfer</a></label></li></ul></li><li><input type=checkbox id=section-f0a392f2f083f28a4991336773716a63 class=toggle>
<label for=section-f0a392f2f083f28a4991336773716a63 class="flex justify-between"><a href=/tech-book/docs/optical-knowledge/>Optical Knowledge</a></label><ul><li><input type=checkbox id=section-18261b95a92d4fa86116243edca4e9fb class=toggle>
<label for=section-18261b95a92d4fa86116243edca4e9fb class="flex justify-between"><a href=/tech-book/docs/optical-knowledge/optical-breakout/>Optical Transceiver(Grey) & Breakout Model</a></label></li></ul></li><li><input type=checkbox id=section-a55840d746138b3d1fedb81acbccdded class=toggle>
<label for=section-a55840d746138b3d1fedb81acbccdded class="flex justify-between"><a href=/tech-book/docs/programming-tips/>Programming Tips</a></label><ul><li><input type=checkbox id=section-f929f1fe13cb5d6cc96ca3e98f9d9777 class=toggle>
<label for=section-f929f1fe13cb5d6cc96ca3e98f9d9777 class="flex justify-between"><a href=/tech-book/docs/programming-tips/c++/>C++ Tips</a></label></li></ul></li><li><input type=checkbox id=section-b35dbf5ebcd4c19926cf5a9aab6c7655 class=toggle>
<label for=section-b35dbf5ebcd4c19926cf5a9aab6c7655 class="flex justify-between"><a href=/tech-book/docs/systemdesign-tips/>SystemDesign-Tips</a></label><ul><li><input type=checkbox id=section-4a618bc3b0b30107f0cec6d3bd6c025f class=toggle>
<label for=section-4a618bc3b0b30107f0cec6d3bd6c025f class="flex justify-between"><a href=/tech-book/docs/systemdesign-tips/code-deployment-system/>Design A Code-Deployment System</a></label></li><li><input type=checkbox id=section-e600754306aa95ce9c5a72b5efec6d7a class=toggle>
<label for=section-e600754306aa95ce9c5a72b5efec6d7a class="flex justify-between"><a href=/tech-book/docs/systemdesign-tips/stock-broker/>Design A Stock-Broker System</a></label></li><li><input type=checkbox id=section-bfa7a29878f65cfbb179e491c1211fa8 class=toggle>
<label for=section-bfa7a29878f65cfbb179e491c1211fa8 class="flex justify-between"><a href=/tech-book/docs/systemdesign-tips/design-amazon/>Design Amazon</a></label></li><li><input type=checkbox id=section-5456837e25872f6352d861a9b5662cb1 class=toggle>
<label for=section-5456837e25872f6352d861a9b5662cb1 class="flex justify-between"><a href=/tech-book/docs/systemdesign-tips/design-slack/>Design Slack</a></label></li><li><input type=checkbox id=section-5a78d16f54536a400b654f17f917bce1 class=toggle>
<label for=section-5a78d16f54536a400b654f17f917bce1 class="flex justify-between"><a href=/tech-book/docs/systemdesign-tips/google-drive/>Google Drive - Design</a></label></li></ul></li></ul><ul><li><a href=/tech-book/posts/>Blog</a></li><li><a href=https://prasenjitmanna.com/ target=_blank rel=noopener>Prasenjit's Blog</a></li><li><a href=https://prasenjitmanna.com/tech-book/ target=_blank rel=noopener>Prasenjit - Tech Book</a></li><li><a href=https://prasenjitmanna.com/upskills/ target=_blank rel=noopener>Prasenjit - Upskills</a></li></ul></nav><script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script></div></aside><div class=book-page><header class=book-header><div class="flex align-center justify-between"><label for=menu-control><img src=/tech-book/svg/menu.svg class=book-icon alt=Menu>
</label><strong>AI/ML Networking</strong>
<label for=toc-control><img src=/tech-book/svg/toc.svg class=book-icon alt="Table of Contents"></label></div><aside class="hidden clearfix"><nav id=TableOfContents><ul><li><a href=#intro>Intro</a><ul><li><a href=#aiml-networking-part-i-rdma-basics>AI/ML Networking Part I: RDMA Basics</a></li><li><a href=#aiml-networking-part-ii-introduction-of-deep-neural-networks>AI/ML Networking: Part-II: Introduction of Deep Neural Networks</a></li><li><a href=#aiml-networking-part-iii-basics-of-neural-networks-training-process>AI/ML Networking: Part-III: Basics of Neural Networks Training Process</a><ul><li><a href=#neural-network-architecture-overview>Neural Network Architecture Overview</a></li><li><a href=#input-layer>Input Layer: </a></li><li><a href=#hidden-layer>Hidden Layer: </a></li><li><a href=#output-layer>Output Layer: </a></li><li><a href=#forwarding-pass>Forwarding Pass </a></li><li><a href=#backpropagation-process>Backpropagation process</a></li></ul></li><li><a href=#aiml-networking-part-iv-convolutional-neural-network-cnn-introduction>AI/ML Networking: Part-IV: Convolutional Neural Network (CNN) Introduction</a><ul><li><a href=#convolution-layer>Convolution Layer</a></li><li><a href=#convolution-layer-example>Convolution Layer Example</a></li><li><a href=#pooling-layer>Pooling Layer</a></li></ul></li></ul></li></ul></nav></aside></header><article class="markdown book-article"><h1 id=intro>Intro
<a class=anchor href=#intro>#</a></h1><h2 id=aiml-networking-part-i-rdma-basics>AI/ML Networking Part I: RDMA Basics
<a class=anchor href=#aiml-networking-part-i-rdma-basics>#</a></h2><p>TBD</p><h2 id=aiml-networking-part-ii-introduction-of-deep-neural-networks>AI/ML Networking: Part-II: Introduction of Deep Neural Networks
<a class=anchor href=#aiml-networking-part-ii-introduction-of-deep-neural-networks>#</a></h2><p><em>Machine Learning (ML)</em> is a subset of <em>Artificial Intelligence (AI)</em>. ML is based on algorithms that allow learning, predicting, and making decisions based on data rather than pre-programmed tasks. ML leverages <em>Deep Neural Networks (DNNs)</em>, which have multiple layers, each consisting of neurons that process information from sub-layers as part of the training process. <em>Large Language Models (LLMs)</em>, such as OpenAI’s GPT (Generative Pre-trained Transformers), utilize ML and Deep Neural Networks.</p><p>For network engineers, it is crucial to understand the fundamental operations and communication models used in ML training processes. To emphasize the importance of this, I quote the Chinese philosopher and strategist Sun Tzu, who lived around 600 BCE, from his work The Art of War.</p><blockquote><p><em>If you know the enemy and know yourself, you need not fear the result of a hundred battles.</em></p></blockquote><p>We don’t have to be data scientists to design a network for AI/ML, but we must understand the operational fundamentals and communication patterns of ML. Additionally, we must have a deep understanding of network solutions and technologies to build a lossless and cost-effective network for enabling efficient training processes.</p><p>In the upcoming two posts, I will explain the basics of: </p><p><em>a) Data Models:</em> Layers and neurons, forward and backward passes, and algorithms. </p><p><em>b) Parallelization Strategies:</em> How training times can be reduced by dividing the model into smaller entities, batches, and even micro-batches, which are processed by several GPUs simultaneously.</p><p>The number of parameters, the selected data model, and the parallelization strategy affect the network traffic that crosses the data center switch fabric.</p><p>After these two posts, we will be ready to jump into the network part. </p><p>At this stage, you may need to read (or re-read) my previous post about Remote Direct Memory Access (RDMA), a solution that enables GPUs to write data from local memory to remote GPUs&rsquo; memory.
<img src=https://prasenjitmanna.com/tech-book/diagrams/ai-ml-dc/ai-ml-dc-1.jpg alt=img|320x271></p><h2 id=aiml-networking-part-iii-basics-of-neural-networks-training-process>AI/ML Networking: Part-III: Basics of Neural Networks Training Process
<a class=anchor href=#aiml-networking-part-iii-basics-of-neural-networks-training-process>#</a></h2><h3 id=neural-network-architecture-overview>Neural Network Architecture Overview
<a class=anchor href=#neural-network-architecture-overview>#</a></h3><p>Deep Neural Networks (DNN) leverage various architectures for training, with one of the simplest and most fundamental being the Feedforward Neural Network (FNN). Figure 2-1 illustrates our simple, three-layer FNN.</p><h3 id=input-layer>Input Layer: 
<a class=anchor href=#input-layer>#</a></h3><p>The first layer doesn’t have neurons, instead the input data parameters X1, X2, and X3 are in this layer, from where they are fed to first hidden layer. </p><h3 id=hidden-layer>Hidden Layer: 
<a class=anchor href=#hidden-layer>#</a></h3><p>The neurons in the hidden layer calculate a weighted sum of the input data, which is then passed through an activation function. In our example, we are using the Rectified Linear Unit (ReLU) activation function. These calculations produce activation values for neurons. The activation value is modified input data value received from the input layer and published to upper layer.</p><h3 id=output-layer>Output Layer: 
<a class=anchor href=#output-layer>#</a></h3><p>Neurons in this layer calculate the weighted sum in the same manner as neurons in the hidden layer, but the result of the activation function is the final output.</p><p>The process described above is known as the Forwarding pass operation. Once the forward pass process is completed, the result is passed through a loss function, where the received value is compared to the expected value. The difference between these two values triggers the backpropagation process. The Loss calculation is the initial phase of Backpropagation process. During backpropagation, the network fine-tunes the weight values , neuron by neuron, from the output layer through the hidden layers. The neurons in the input layer do not participate in the backpropagation process because they do not have weight values to be adjusted.</p><p>After the backpropagation process, a new iteration of the forward pass begins from the first hidden layer. This loop continues until the received and expected values are close enough to expected value, indicating that the training is complete.
<img src=https://prasenjitmanna.com/tech-book/diagrams/ai-ml-dc/2-1.jpg alt=img|320x271></p><p><strong>Figure 2-1:</strong> <em>Deep Neural Network Basic Structure and Operations.</em></p><h3 id=forwarding-pass>Forwarding Pass 
<a class=anchor href=#forwarding-pass>#</a></h3><p>Next, let&rsquo;s examine the operation of a Neural Network in more detail. Figure 2-2 illustrates a simple, three-layer Feedforward Neural Network (FNN) data model. The input layer has two neurons, H1 and H2, each receiving one input data value: a value of one (1) is fed to neuron H1 by input neuron X1, and a value of zero (0) is fed to neuron H2 by input neuron X2. The neurons in the input layer do not calculate a weighted sum or an activation value but instead pass the data to the next layer, which is the first hidden layer.</p><p>The hidden layer in our example consists of two neurons. These neurons use the ReLU activation function to calculate the activation value. During the initialization phase, the weight values for these neurons are assigned using the He Initialization method, which is often used with the ReLU function. The He Initialization method calculates the variance as 2/<em>n</em> where <em>n</em> is the number of neurons in the previous layer. In this example, with two input neurons, this gives a variance of  1 (=2/2). The weights are then drawn from a normal distribution ~<em>N(0,√variance),</em> which in this case is  ~N(0,1). Basically, this means that the randomly generated weight values are centered around zero with a standard deviation of one.</p><p>In Figure 2-2, the weight value for neuron H3 in the hidden layer is 0.5 for both input sources X1 (input data 1) and X2 (input data 0). Similarly, for the hidden layer neuron H4, the weight value is 1 for both input sources X1 (input data 1) and X2 (input data 0). Neurons in the hidden and output layers also have a bias variable. If the input to a neuron is zero, the output would also be zero if there were no bias. The bias ensures that a neuron can still produce a meaningful output even when the input is zero (i.e., the neuron is inactive). Neurons H3 and O5 have a bias value of 0.5, while neuron H4 has a bias value of 0 (I am using zero for simplify the calculation). </p><p>Let’s start the forward pass process from neuron H3 in the hidden layer. First, we calculate the weighted sum using the formula below, where Z3 represents the weighted sum of input. Here, Xn is the actual input data value received from the input layer’s neuron, and Wn  is the weight associated with that particular input neuron.</p><p>The weighted sum calculation (Z3) for neuron H3:</p><pre tabindex=0><code>Z3 = (X1 ⋅ W31) + (X2 ⋅ W32) + b3

Given:
Z3 = (1 ⋅ 0.5) + (0 ⋅ 0.5) + 0
Z3 = 0.5 + 0 + 0
Z3 = 0.5
</code></pre><p>To get the activation value a3 (shown as H3=0.5 in figure), we apply the ReLU function. The ReLU function outputs zero (0) if the calculated weighted sum Z is less than or equal to zero; otherwise, it outputs the value of the weighted sum Z.</p><p>The activation value a3 for H3 is:</p><blockquote><p><em>ReLU (Z3) = ReLU (0.5) = 0.5</em></p></blockquote><p>The weighted sum calculation for neuron H4:</p><pre tabindex=0><code>Z4 = (X1 ⋅ W41) + (X2 ⋅ W42) + b4

Given:
Z4 = (1 ⋅ 1) + (0 ⋅1) + 0.5
Z4 = 1 + 0 + 0.5
Z4 = 1.5
</code></pre><p>The activation value using ReLU for Z4 is:</p><blockquote><p><em>ReLU (Z4) = ReLU (1.5) = 1.5</em></p></blockquote><p><img src=https://prasenjitmanna.com/tech-book/diagrams/ai-ml-dc/2-2.jpg alt=img|320x271></p><p><strong>Figure 2-2:</strong> <em>Forwarding Pass on Hidden Layer.</em></p><p>After neurons H3 and H4 publish their activation values to neuron O5 in the output layer, O5 calculates the weighted sum Z5 for inputs with weights W53=1and W54=1. Using Z5, it calculates the output using the ReLU function. The difference between the received output value (Yr) and the expected value (Ye) triggers a backpropagation process. In our example, Yr−Ye=0.5.</p><h3 id=backpropagation-process>Backpropagation process
<a class=anchor href=#backpropagation-process>#</a></h3><p>The loss function measures the difference between the predicted output and the actual expected output. The loss function value indicates how well the neural network is performing. A high loss value means the network&rsquo;s predictions are far from the actual values, while a low loss value means the predictions are close.</p><p>After calculating the loss, backpropagation is initiated to minimize this loss. Backpropagation involves calculating the gradient of the loss function with respect to each weight and bias in the network. This step is crucial for adjusting the weights and biases to reduce the loss in subsequent forwarding pass iterations.</p><p>Loss function is calculated using the formula below:</p><pre tabindex=0><code>Loss (L) = (H3 x W53 + H4 x W54 + b5 – Ye)2
Given:
L = (0.5 x 1 + 1.5 x 1 + 0.5 - 2)2
L = (0.5 + 1.5 + 0.5 - 2)2
L = 0.52
L= 0.25
</code></pre><p><img src=https://prasenjitmanna.com/tech-book/diagrams/ai-ml-dc/2-3.jpg alt=img|320x271></p><p><strong>Figure 2-3:</strong> <em>Forwarding Pass on Output Layer.</em></p><p>The result of the loss function is then fed into the gradient calculation process, where we compute the gradient of the loss function with respect to each weight and bias in the network. The gradient calculation result is then used to fine-tune the old weight values. The Eta hyper-parameter <em>η</em> (the learning rate) controls the step size during weight updates in the backpropagation process, balancing the speed of convergence with the stability of training. In our example, we are using a learning rate of 1/100 = 0.01. The term hyper-parameters refers to parameters that affect the final result.</p><p>First, we compute the partial derivative of the loss function (gradient calculation) with respect to the old weight values. The following example shows the gradient calculation for weight W53. The same computation applies to W54  and b3.</p><p><strong>Gradient Calculation:</strong></p><pre tabindex=0><code>∂L = 2W53 x (Yr – Ye)

∂W53
Given
= 2 x 0.5 x (2.5 - 2)
= 1 x 0.5
= 0.5
</code></pre><p><strong>New weight value calculation.</strong></p><pre tabindex=0><code> W53 (new) = W53(old) – η x ∂L/∂W53
 
 Given:
 W53 (new) = 1–0.01 x 0.5
 W53 (new) = 0.995
</code></pre><p><img src=https://prasenjitmanna.com/tech-book/diagrams/ai-ml-dc/2-4.jpg alt=img|320x271></p><p><strong>Figure 2-4:</strong> <em>Backpropagation - Gradient Calculation and New Weight Value Computation.</em></p><p>Figure 2-5 shows the formulas for calculating the new bias b3. The process is the same than what was used with updating the weight values.</p><p><img src=https://prasenjitmanna.com/tech-book/diagrams/ai-ml-dc/2-5.jpg alt=img|320x271></p><p><strong>Figure 2-5:</strong> <em>Backpropagation - Gradient Calculation and New Bias Computation.</em></p><p>After updating the weights and biases, the backpropagation process moves to the hidden layer. Gradient computation in the hidden layer is more complex because the loss function only includes weights from the output layer as you can see from the Loss function formula below:</p><p>Loss (L) = (H3 x W53 + H4 x W54 + b5 – Ye)2</p><p>The formula for computing the weights and biases for neurons in the hidden layers uses the chain rule. The mathematical formula shown below, but the actual computation is beyond the scope of this chapter.</p><p>∂L   =    ∂L  x  ∂H3    </p><p>∂W31   ∂H3    ∂W31    </p><p>After the backpropagation process is completed, the next iteration of the forward pass starts. This loop continues until the received result is close enough to the expected result.</p><p>If the size of the input data exceeds the GPU’s memory capacity or if the computing power of one GPU is insufficient for the data model, we need to decide on a parallelization strategy. This strategy defines how the training workload is distributed across several GPUs. Parallelization impacts network load if we need more GPUs than are available on one server. Dividing the workload among GPUs within a single GPU-server or between multiple GPU-servers triggers synchronization of calculated gradients between GPUs. When the gradient is calculated, the GPUs synchronize the results and compute the average gradient, which is then used to update the weight values.</p><p>The upcoming chapter introduces pipeline parallelization and synchronization processes in detail. We will also discuss why lossless connection is required for AI/ML.</p><h2 id=aiml-networking-part-iv-convolutional-neural-network-cnn-introduction>AI/ML Networking: Part-IV: Convolutional Neural Network (CNN) Introduction
<a class=anchor href=#aiml-networking-part-iv-convolutional-neural-network-cnn-introduction>#</a></h2><p>Feed-forward Neural Networks are suitable for simple tasks like basic time series prediction without long-term relationships. However, FNNs is not a one-size-fits-all solution. For instance, digital image training process uses pixel values of image as input data. Consider training a model to recognize a high resolution (600 dpi), 3.937 x 3.937 inches digital RGB (red, green, blue) image. The number of input parameters can be calculated as follows:</p><blockquote><p>Width: 3.937 in x 600 ≈ 2362 pixels<br>Height: 3.937 in x 600 ≈ 2362 pixels<br>Pixels in image: 2362 x 2362 = 5,579,044 pixels<br>RGB (3 channels): 5,579,044 pxls x 3 channels = 16 737 132<br>Total input parameters: 16 737 132<br>Memory consumption: ≈ 16 MB</p></blockquote><p>FNNs are not ideal for digital image training. If we use FNN for training in our example, we fed 16,737,132 input parameters to the first hidden layer, each having unique weight. For image training, there might be thousands of images, handling millions of parameters demands significant computation cycles and is a memory-intensive process. Besides, FNNs treat each pixel as an independent unit. Therefore, FNN algorithm does not understand dependencies between pixels and cannot recognize the same image if it shifts within the frame. Besides, FNN does not detect edges and other crucial details. </p><p>A better model for training digital images is Convolutional Neural Networks (CNNs). Unlike in FFN neural networks where each neuron has a unique set of weights, CNNs use the same set of weights (Kernel/Filter) across different regions of the image, which reduces the number of parameters. Besides, CNN algorithm understands the pixel dependencies and can recognize patterns and objects regardless of their position in the image. </p><p>The input data processing in CNNs is hierarchical. The first layer, convolutional layers, focuses on low-level features such as textures and edges. The second layer, pooling layer, captures higher-level features like shapes and objects. These two layers significantly reduce the input data parameters before they are fed into the neurons in the first hidden layer, the fully connected layer, where each neuron has unique weights (like FNNs).</p><p><img src=https://prasenjitmanna.com/tech-book/diagrams/ai-ml-dc/3-0.jpg alt=img|320x271></p><h3 id=convolution-layer>Convolution Layer
<a class=anchor href=#convolution-layer>#</a></h3><p>The convolution process uses a shared kernel (also known as filters), which functions similarly to a neuron in a feed-forward neural network. The kernel&rsquo;s coverage area, 3x3 in our example, defines how many pixels of an input image is covered at a given stride. The kernel assigns a unique weight (w) to each covered pixel (x) in a one-to-one mapping fashion and calculates the weighted sum (z) from the input data. For instance, in figure 3-1 the value of the pixel W1 is multiplied with the weight value W1 (X1W1), and pixel X2 is multiplies with weight value W2 (X2W2) and so on. Then the results are summed, which returns a weighted sum Z.  The result Z is then passed through the ReLU function, which defines the value of the new pixel (P1). This new pixel is then placed into a new image matrix.</p><p><img src=https://prasenjitmanna.com/tech-book/diagrams/ai-ml-dc/3-1.jpg alt=img|320x271></p><p><strong>Figure 3-1:</strong> <em>CNN Overview – Convolution, Initial State (Stride 0).</em></p><p>After calculating the new pixel value for the initial coverage area with stride zero, the kernel shifts to the right by the number of steps defined in the kernel&rsquo;s stride value. In our example, the stride is set to one, and the kernel moves one step to the right, covering pixels shown in Figure 3-2. Then the weighted sum is (z) calculated and run through the ReLU function, and the second pixel is added to the new matrix. Since there are no more pixels to the right, the kernel moves down by one step and returns to the first column (Figure 3-3).</p><p><img src=https://prasenjitmanna.com/tech-book/diagrams/ai-ml-dc/3-2.jpg alt=img|320x271></p><p><strong>Figure 3-2:</strong> <em>CNN Overview – Convolution, Second State (Stride 1).</em></p><p>Figures 3-3 and 3-4 shows the last two steps of the convolution. Notice that we have used the same weight values in each iteration. In the initial state weight w1 was associated with the first pixel (X1W1), and in the second phase with the second pixel (X2W1) and so on. The new image matrix produced by the convolutional process have decreased the 75% from the original digital image. </p><p><img src=https://prasenjitmanna.com/tech-book/diagrams/ai-ml-dc/3-3.jpg alt=img|320x271></p><p><strong>Figure 3-3:</strong> CNN Overview – Convolution, Third State (Stride 2).</p><p><img src=https://prasenjitmanna.com/tech-book/diagrams/ai-ml-dc/3-4.jpg alt=img|320x271></p><p><strong>Figure 3-4:</strong> <em>CNN Overview – Convolution, Fourth State (Stride 3).</em></p><p>If we don&rsquo;t want to decrease the size of the new matrix, we must use padding. Padding adds pixels to the edges of the image. For example, a padding value of one (1) adds one pixel to the image edges, providing a new matrix that is the same size as the original image.</p><p><img src=https://prasenjitmanna.com/tech-book/diagrams/ai-ml-dc/3-5.jpg alt=img|320x271></p><p><strong>Figure 3-5:</strong> <em>CNN Overview – Padding.</em></p><p>Figure 3-6 illustrates the progression of the convolution layer from the initial state (which I refer to as stride 0) to the final phase, stride 3. The kernel covers a 3x3 pixel area in each phase and moves with a stride of 1. I use the notation SnXn to denote the stride and the specific pixel. For example, in the initial state, the first pixel covered by the kernel is labeled as S0X1, and the last pixel is labeled as S0X11.</p><p>When the kernel shifts to the left, covering the next region, the first pixel is marked as S1X2 and the last as S1X12. The same notation is applied to the weighted sum calculation. The weighted value for the first pixel is represented as (S0X1) · W1 = Z1 and for the last one as (S0X11) · W9 = Z9. The weighted input for all pixel values is then summed, and a bias is added to obtain the weighted sum for the given stride.</p><p>In the initial state, this calculation results in = Z0, which is passed through the ReLU function. The output of this function provides the value for the first pixel in the new image matrix.</p><p><img src=https://prasenjitmanna.com/tech-book/diagrams/ai-ml-dc/3-6.jpg alt=img|320x271></p><p><strong>Figure 3-6:</strong> <em>CNN Overview – Convolution Summary.</em></p><h3 id=convolution-layer-example>Convolution Layer Example
<a class=anchor href=#convolution-layer-example>#</a></h3><p>In Figure 3-7, we have a simple 12x12 = 144 pixels grayscale image representing the letter &ldquo;H.&rdquo; In the image, the white pixels have a binary value of 255, the gray pixels have a binary value of 87, and the darkest pixels have a binary value of 2. Our kernel size is 4x4, covering 16 pixels in each stride. Because the image is grayscale, we only have one channel. The kernel uses the ReLU activation function to determine the value for the new pixel. </p><p>Initially, at stride 0, the kernel is placed over the first region in the image. The kernel has a unique weight value for each pixel it covers, and it calculates the weighted sum for all 16 pixels. The value of the first pixel (X1 = 87) is multiplied by its associated kernel weight (W1 = 0.12), which gives us a new value of 10.4. This computation runs over all 16 pixels covered by the kernel (results shown in Figure 3-7). The new values are then summed, and a bias is added, giving a weighted sum of Z0 = 91.4. Because the value of Z0 is positive, the ReLU function returns an activation value of 91.4 (if Z > 0, Z = Z; otherwise, Z = 0). The activation value of 91.4 becomes the value of our new pixel in the new image matrix.</p><p><img src=https://prasenjitmanna.com/tech-book/diagrams/ai-ml-dc/3-7.jpg alt=img|320x271></p><p><strong>Figure 3-7:</strong> <em>Convolution Layer Operation Example – Stride 0 (Initial State).</em></p><p>Next, the kernel shifts one step to the right (Stride 1) and multiplies the pixel values by the associated weights. The changing parameters are the values of the pixels, while the kernel weight values remain the same. After the multiplication process is done and the weighted sum is calculated, the result is run through the ReLU function. At this stride, the result of the weighted sum (Z1) is negative, so the ReLU function returns zero (0). This value is then added to the matrix. At this phase, we have two new pixels in the matrix.</p><p><img src=https://prasenjitmanna.com/tech-book/diagrams/ai-ml-dc/3-8.jpg alt=img|320x271></p><p><strong>Figure 3-8:</strong> <em>Convolution Layer Operation Example – Stride 1.</em></p><p>The next four figures 3-9, 3-10, and 3-11 illustrates how the kernel is shifted over the input digital image and producing a new 9x9 image matrix.</p><p><img src=https://prasenjitmanna.com/tech-book/diagrams/ai-ml-dc/3-9.jpg alt=img|320x271></p><p><strong>Figure 3-9:</strong> <em>Convolution Layer Operation Example – Stride 2.</em></p><p><img src=https://prasenjitmanna.com/tech-book/diagrams/ai-ml-dc/3-10.jpg alt=img|320x271></p><p><strong>Figure 3-10:</strong> <em>Convolution Layer Operation Example – Stride 8.</em></p><p><img src=https://prasenjitmanna.com/tech-book/diagrams/ai-ml-dc/3-11.jpg alt=img|320x271></p><p><strong>Figure 3-11:</strong> <em>Convolution Layer Operation Example – Stride 10.</em></p><p>Figure 3-12 illustrates the completed convolutional layer computation. At this stage, the number of pixels in the original input image has decreased from 144 to 81, representing a reduction of 56.25%.</p><p><img src=https://prasenjitmanna.com/tech-book/diagrams/ai-ml-dc/3-12.jpg alt=img|320x271></p><p><strong>Figure 3-12:</strong> <em>Convolution Layer Operation Example – The Last Stride.</em> </p><h3 id=pooling-layer>Pooling Layer
<a class=anchor href=#pooling-layer>#</a></h3><p>After the original image is processed by the convolution layer, the resulting output is used as input data for the next layer, the pooling layer. The pooling layer performs a simpler operation than the convolution layer. Like the convolution layer, the pooling layer uses a kernel to generate new values. However, instead of applying a convolution operation, the pooling layer selects the highest value within the kernel (if MaxPooling is applied) or computes the average of the values covered by the kernel (Average Pooling).</p><p>In this example, we use MaxPooling with a kernel size of 2x2 and a stride of 2. The first pixel is selected from values 91, 0, 112, and 12, corresponding to pixels in positions 1, 2, 10, and 11, respectively. Since the pixel at position 10 has the highest value (112), it is selected for the new matrix.</p><p><img src=https://prasenjitmanna.com/tech-book/diagrams/ai-ml-dc/3-13.jpg alt=img|320x271></p><p><strong>Figure 3-13:</strong> <em>Pooling Layer – Stride 0 (Initial Phase).</em></p><p>After selecting the highest value from the initial phase, the kernel moves to the next region, covering the values 252, 153, 212, and 52. The highest value, 252, is then placed into the new matrix. </p><p><img src=https://prasenjitmanna.com/tech-book/diagrams/ai-ml-dc/3-14.jpg alt=img|320x271></p><p><strong>Figure 3-14:</strong> <em>Pooling Layer – Stride 1.</em></p><p>Figure 3-15 illustrates how MaxPooling progresses to the third region, covering the values 141, 76, 82, and 35. The highest value, 141, is then placed into the matrix.</p><p><img src=https://prasenjitmanna.com/tech-book/diagrams/ai-ml-dc/3-15.jpg alt=img|320x271></p><p><strong>Figure 3-15:</strong> <em>Pooling Layer – Stride 2.</em></p><p>Figure 3-16 describes how the original 12x12 (144 pixels) image is first processed by the convolution layer, reducing it to a 9x9 (81 pixels) matrix, and then by the pooling layer, further reducing it to a 5x5 (25 pixels) matrix.</p><p><img src=https://prasenjitmanna.com/tech-book/diagrams/ai-ml-dc/3-16.jpg alt=img|320x271></p><p><strong>Figure 3-16:</strong> <em>CNN Convolution and Pooling Layer Results.</em></p><p>As the final step, the matrix generated by the pooling layer is flattened and used as input for the neurons in the fully connected layer. This means we have 25 input neurons, each with a unique weight assigned to every input parameter. The neurons in the input layer calculate the weighted sum, which neurons then use to determine the activation value. This activation value serves as the input data for the output layer. The neurons in the output layer produce the result based on their calculations, with the output H proposed by three output neurons.</p><p><img src=https://prasenjitmanna.com/tech-book/diagrams/ai-ml-dc/3-17.jpg alt=img|320x271></p><p><strong>Figure 3-17:</strong> <em>The Model of Convolution Neural Network (CNN).</em></p><p><strong>References:</strong></p><ul><li><a href=https://nwktimes.blogspot.com/2024/06/aiml-networking-part-i-rdma-basics.html>https://nwktimes.blogspot.com/2024/06/aiml-networking-part-i-rdma-basics.html</a></li><li><a href=https://nwktimes.blogspot.com/2024/07/aiml-networking-part-ii-introduction-of.html>https://nwktimes.blogspot.com/2024/07/aiml-networking-part-ii-introduction-of.html</a></li><li><a href=https://nwktimes.blogspot.com/2024/07/aiml-networking-part-iii-basics-of.html>https://nwktimes.blogspot.com/2024/07/aiml-networking-part-iii-basics-of.html</a></li><li><a href=https://nwktimes.blogspot.com/2024/08/aiml-networking-part-iv-convolutional.html>https://nwktimes.blogspot.com/2024/08/aiml-networking-part-iv-convolutional.html</a></li></ul></article><footer class=book-footer><div class="flex flex-wrap justify-between"><div><a class="flex align-center" href=https://github.com/prmanna/tech-book/commit/6e8ce302dcfbac50b2aca7f69cdf4a9a5412dc11 title='Last modified by Prasenjit Manna | May 8, 2025' target=_blank rel=noopener><img src=/tech-book/svg/calendar.svg class=book-icon alt>
<span>May 8, 2025</span></a></div></div><script>(function(){function e(e){const t=window.getSelection(),n=document.createRange();n.selectNodeContents(e),t.removeAllRanges(),t.addRange(n)}document.querySelectorAll("pre code").forEach(t=>{t.addEventListener("click",function(){if(window.getSelection().toString())return;e(t.parentElement),navigator.clipboard&&navigator.clipboard.writeText(t.parentElement.textContent)})})})()</script></footer><div class=book-comments></div><label for=menu-control class="hidden book-menu-overlay"></label></div><aside class=book-toc><div class=book-toc-content><nav id=TableOfContents><ul><li><a href=#intro>Intro</a><ul><li><a href=#aiml-networking-part-i-rdma-basics>AI/ML Networking Part I: RDMA Basics</a></li><li><a href=#aiml-networking-part-ii-introduction-of-deep-neural-networks>AI/ML Networking: Part-II: Introduction of Deep Neural Networks</a></li><li><a href=#aiml-networking-part-iii-basics-of-neural-networks-training-process>AI/ML Networking: Part-III: Basics of Neural Networks Training Process</a><ul><li><a href=#neural-network-architecture-overview>Neural Network Architecture Overview</a></li><li><a href=#input-layer>Input Layer: </a></li><li><a href=#hidden-layer>Hidden Layer: </a></li><li><a href=#output-layer>Output Layer: </a></li><li><a href=#forwarding-pass>Forwarding Pass </a></li><li><a href=#backpropagation-process>Backpropagation process</a></li></ul></li><li><a href=#aiml-networking-part-iv-convolutional-neural-network-cnn-introduction>AI/ML Networking: Part-IV: Convolutional Neural Network (CNN) Introduction</a><ul><li><a href=#convolution-layer>Convolution Layer</a></li><li><a href=#convolution-layer-example>Convolution Layer Example</a></li><li><a href=#pooling-layer>Pooling Layer</a></li></ul></li></ul></li></ul></nav></div></aside></main></body></html>