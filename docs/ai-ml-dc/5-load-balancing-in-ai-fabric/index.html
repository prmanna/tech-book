<!doctype html><html lang=en-us dir=ltr><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="
  AI for Network Engineers: Understanding Flow, Flowlet, and Packet-Based Load Balancing
  #

Though BGP supports the traditional Flow-based Layer 3 Equal Cost Multi-Pathing (ECMP) traffic load balancing method, it is not the best fit for a RoCEv2-based AI backend network. This is because GPU-to-GPU communication creates massive elephant flows, which RDMA-capable NICs transmit at line rate. These flows can easily cause congestion in the backend network."><meta name=theme-color media="(prefers-color-scheme: light)" content="#ffffff"><meta name=theme-color media="(prefers-color-scheme: dark)" content="#343a40"><meta name=color-scheme content="light dark"><meta property="og:url" content="https://prasenjitmanna.com/tech-book/docs/ai-ml-dc/5-load-balancing-in-ai-fabric/"><meta property="og:site_name" content="Technical Book"><meta property="og:title" content="5. Load Balancing in AI Fabric"><meta property="og:description" content=" AI for Network Engineers: Understanding Flow, Flowlet, and Packet-Based Load Balancing # Though BGP supports the traditional Flow-based Layer 3 Equal Cost Multi-Pathing (ECMP) traffic load balancing method, it is not the best fit for a RoCEv2-based AI backend network. This is because GPU-to-GPU communication creates massive elephant flows, which RDMA-capable NICs transmit at line rate. These flows can easily cause congestion in the backend network."><meta property="og:locale" content="en_us"><meta property="og:type" content="article"><meta property="article:section" content="docs"><meta property="article:modified_time" content="2025-05-05T10:12:36+05:30"><title>5. Load Balancing in AI Fabric | Technical Book</title>
<link rel=manifest href=/tech-book/manifest.json><link rel=icon href=/tech-book/favicon.png><link rel=canonical href=https://prasenjitmanna.com/tech-book/docs/ai-ml-dc/5-load-balancing-in-ai-fabric/><link rel=stylesheet href=/tech-book/book.min.a61cdb2979f3c2bece54ef69131fba427dd57d55c232d3bb5fdb62ac41aa8354.css integrity="sha256-phzbKXnzwr7OVO9pEx+6Qn3VfVXCMtO7X9tirEGqg1Q=" crossorigin=anonymous><script defer src=/tech-book/fuse.min.js></script><script defer src=/tech-book/en.search.min.bcfbf42b14827268353a4f33c28a0ffb96281b2852f1d401d0d36b344c7ceedc.js integrity="sha256-vPv0KxSCcmg1Ok8zwooP+5YoGyhS8dQB0NNrNEx87tw=" crossorigin=anonymous></script></head><body dir=ltr><input type=checkbox class="hidden toggle" id=menu-control>
<input type=checkbox class="hidden toggle" id=toc-control><main class="container flex"><aside class=book-menu><div class=book-menu-content><nav><h2 class=book-brand><a class="flex align-center" href=/tech-book/><img src=/tech-book/logo.png alt=Logo><span>Technical Book</span></a></h2><div class="book-search hidden"><input type=text id=book-search-input placeholder=Search aria-label=Search maxlength=64 data-hotkeys=s/><div class="book-search-spinner hidden"></div><ul id=book-search-results></ul></div><script>document.querySelector(".book-search").classList.remove("hidden")</script><ul><li><input type=checkbox id=section-99f552133860bc21797a47fe73e93434 class=toggle>
<label for=section-99f552133860bc21797a47fe73e93434 class="flex justify-between"><a href=/tech-book/docs/5g/>5G</a></label><ul><li><input type=checkbox id=section-dfc790b73acb0410a0114547cbf5af32 class=toggle>
<label for=section-dfc790b73acb0410a0114547cbf5af32 class="flex justify-between"><a href=/tech-book/docs/5g/5g-intro/>An Overview of 5G Networking</a></label></li></ul></li><li><input type=checkbox id=section-7c4a3b16aeeb5b7194b232c1eef2f4fb class=toggle>
<label for=section-7c4a3b16aeeb5b7194b232c1eef2f4fb class="flex justify-between"><a href=/tech-book/docs/algorithms/>Algorithms</a></label><ul><li><input type=checkbox id=section-8956d82fbe6869140758f7e8679174bc class=toggle>
<label for=section-8956d82fbe6869140758f7e8679174bc class="flex justify-between"><a href=/tech-book/docs/algorithms/breadth-first-search/>Breadth First Search</a></label></li><li><input type=checkbox id=section-5a049cfad1740f3fd30565524385fa57 class=toggle>
<label for=section-5a049cfad1740f3fd30565524385fa57 class="flex justify-between"><a href=/tech-book/docs/algorithms/depth-first-search/>Depth First Search</a></label></li><li><input type=checkbox id=section-ebc049f26d82165be8c6f1f9e504e799 class=toggle>
<label for=section-ebc049f26d82165be8c6f1f9e504e799 class="flex justify-between"><a href=/tech-book/docs/algorithms/easy/>Easy Complexity</a></label></li><li><input type=checkbox id=section-1071946392bd1f431993e950147fa054 class=toggle>
<label for=section-1071946392bd1f431993e950147fa054 class="flex justify-between"><a href=/tech-book/docs/algorithms/priority-queue-and-heap/>Priority Queue and Heap</a></label></li><li><input type=checkbox id=section-08afbeb294c43ca4908c1c89a4be9d0a class=toggle>
<label for=section-08afbeb294c43ca4908c1c89a4be9d0a class="flex justify-between"><a href=/tech-book/docs/algorithms/two-pointers/>Two Pointers & Sliding Window</a></label></li><li><input type=checkbox id=section-ef36c7c4f7e0dec6525068c3c409100c class=toggle>
<label for=section-ef36c7c4f7e0dec6525068c3c409100c class="flex justify-between"><a href=/tech-book/docs/algorithms/medium/>Medium Complexity</a></label></li></ul></li><li><input type=checkbox id=section-8c7c5c4a8382299873178820b1d91be1 class=toggle checked>
<label for=section-8c7c5c4a8382299873178820b1d91be1 class="flex justify-between"><a href=/tech-book/docs/ai-ml-dc/>Data Center Networking for AI Clusters</a></label><ul><li><input type=checkbox id=section-433ccede4154db01f6c601940d2949e0 class=toggle>
<label for=section-433ccede4154db01f6c601940d2949e0 class="flex justify-between"><a href=/tech-book/docs/ai-ml-dc/1-ai-ml-networking/>1. AI/ML Networking</a></label></li><li><input type=checkbox id=section-65f71f2455a94ea3d1143666d556b0ed class=toggle>
<label for=section-65f71f2455a94ea3d1143666d556b0ed class="flex justify-between"><a href=/tech-book/docs/ai-ml-dc/2-ai-deep-learning-basics/>2. Deep Learning Basics | Artificial Neuron</a></label></li><li><input type=checkbox id=section-f11d3aa2e337730e1e3345f8530fe134 class=toggle>
<label for=section-f11d3aa2e337730e1e3345f8530fe134 class="flex justify-between"><a href=/tech-book/docs/ai-ml-dc/3-challenges-in-ai-fabric/>3. Challenges in AI Fabric Design</a></label></li><li><input type=checkbox id=section-e28420ec7507646128f3695b6f9badbb class=toggle>
<label for=section-e28420ec7507646128f3695b6f9badbb class="flex justify-between"><a href=/tech-book/docs/ai-ml-dc/4-congestion-avoidance-in-ai-fabric/>4. Congestion Avoidance in AI Fabric</a></label></li><li><input type=checkbox id=section-67bb7cbb1dd95e59f8515201219c090f class=toggle checked>
<label for=section-67bb7cbb1dd95e59f8515201219c090f class="flex justify-between"><a href=/tech-book/docs/ai-ml-dc/5-load-balancing-in-ai-fabric/ class=active>5. Load Balancing in AI Fabric</a></label></li><li><input type=checkbox id=section-5f3e07f6cf7921e5291ff7894e06b19b class=toggle>
<label for=section-5f3e07f6cf7921e5291ff7894e06b19b class="flex justify-between"><a href=/tech-book/docs/ai-ml-dc/6-backend-network-topologies-for-ai-fabric/>6. Backend Network Topologies for AI Fabrics</a></label></li></ul></li><li><input type=checkbox id=section-3272b2d28b2b247027bf478619ca416f class=toggle>
<label for=section-3272b2d28b2b247027bf478619ca416f class="flex justify-between"><a href=/tech-book/docs/data-center/>Data Center Tips</a></label><ul><li><input type=checkbox id=section-984f932c7aba4f0a1841e8413165c947 class=toggle>
<label for=section-984f932c7aba4f0a1841e8413165c947 class="flex justify-between"><a href=/tech-book/docs/data-center/data-center-ethernet/>Data Center Ethernet</a></label></li><li><input type=checkbox id=section-bc5ac88940153a700e63e3be886c63cc class=toggle>
<label for=section-bc5ac88940153a700e63e3be886c63cc class="flex justify-between"><a href=/tech-book/docs/data-center/data-center-technologies/>Data Center Technologies</a></label></li><li><input type=checkbox id=section-86fde1ddf43700ef8191e11c59a82cf1 class=toggle>
<label for=section-86fde1ddf43700ef8191e11c59a82cf1 class="flex justify-between"><a href=/tech-book/docs/data-center/data-center-network-virtualization/>Network Virtualization in Cloud Data Centers</a></label></li></ul></li><li><input type=checkbox id=section-ddf784688e0c6d5abb681d2c57851559 class=toggle>
<label for=section-ddf784688e0c6d5abb681d2c57851559 class="flex justify-between"><a href=/tech-book/docs/manageability/>Manageability</a></label><ul><li><input type=checkbox id=section-33ac730897af6feca81c1fdb7869c57e class=toggle>
<label for=section-33ac730897af6feca81c1fdb7869c57e class="flex justify-between"><a href=/tech-book/docs/manageability/why-grpc-on-http2/>gRPC on HTTP/2</a></label></li></ul></li><li><input type=checkbox id=section-c14ae944424668ef125e10cd791a3d3d class=toggle>
<label for=section-c14ae944424668ef125e10cd791a3d3d class="flex justify-between"><a href=/tech-book/docs/networking-tips/>Networking Tips</a></label><ul><li><input type=checkbox id=section-78fdf21c03c55935d3146441b06faf3e class=toggle>
<label for=section-78fdf21c03c55935d3146441b06faf3e class="flex justify-between"><a href=/tech-book/docs/networking-tips/dns/>DNS Overview</a></label></li><li><input type=checkbox id=section-bbcb027a658dc7a2333d59078ee507f9 class=toggle>
<label for=section-bbcb027a658dc7a2333d59078ee507f9 class="flex justify-between"><a href=/tech-book/docs/networking-tips/ecmp/>ECMP Load Balancing</a></label></li><li><input type=checkbox id=section-3b39b86f18b3451e5b8a1b81c369549c class=toggle>
<label for=section-3b39b86f18b3451e5b8a1b81c369549c class="flex justify-between"><a href=/tech-book/docs/networking-tips/ip-fragmentation/>IP Fragmentation - IPv4 & IPv6</a></label></li><li><input type=checkbox id=section-c6d06c54cc91b0bc3f948d33b437fa8b class=toggle>
<label for=section-c6d06c54cc91b0bc3f948d33b437fa8b class="flex justify-between"><a href=/tech-book/docs/networking-tips/ip-tos-dscp/>IP Precedence And TOS | DSCP</a></label></li><li><input type=checkbox id=section-5f3260c76dd37177e3f89057bfe520ae class=toggle>
<label for=section-5f3260c76dd37177e3f89057bfe520ae class="flex justify-between"><a href=/tech-book/docs/networking-tips/traceroute/>Linux traceroute tool</a></label></li><li><input type=checkbox id=section-a26cc3fafb36cbc55527adf39ec83849 class=toggle>
<label for=section-a26cc3fafb36cbc55527adf39ec83849 class="flex justify-between"><a href=/tech-book/docs/networking-tips/mlag/>Multi Chassis Link Aggregation Basics</a></label></li><li><input type=checkbox id=section-36409a0abcb2d4d4baf2e0b682d1a5dd class=toggle>
<label for=section-36409a0abcb2d4d4baf2e0b682d1a5dd class="flex justify-between"><a href=/tech-book/docs/networking-tips/qos/>QoS</a></label></li><li><input type=checkbox id=section-db41e3547d316b01acf9a0ce9c04ef34 class=toggle>
<label for=section-db41e3547d316b01acf9a0ce9c04ef34 class="flex justify-between"><a href=/tech-book/docs/networking-tips/spine-leaf-arch/>Spine-leaf Architecture Basics</a></label></li><li><input type=checkbox id=section-0eb0d409074a76b8cb02624655e2434d class=toggle>
<label for=section-0eb0d409074a76b8cb02624655e2434d class="flex justify-between"><a href=/tech-book/docs/networking-tips/tcp-congestion/>TCP Congestion Control</a></label></li><li><input type=checkbox id=section-3d1710947b3c5be1a1cc33d88fcc6f54 class=toggle>
<label for=section-3d1710947b3c5be1a1cc33d88fcc6f54 class="flex justify-between"><a href=/tech-book/docs/networking-tips/tcp-data-transfer/>TCP Data Transfer</a></label></li></ul></li><li><input type=checkbox id=section-f0a392f2f083f28a4991336773716a63 class=toggle>
<label for=section-f0a392f2f083f28a4991336773716a63 class="flex justify-between"><a href=/tech-book/docs/optical-knowledge/>Optical Knowledge</a></label><ul><li><input type=checkbox id=section-18261b95a92d4fa86116243edca4e9fb class=toggle>
<label for=section-18261b95a92d4fa86116243edca4e9fb class="flex justify-between"><a href=/tech-book/docs/optical-knowledge/optical-breakout/>Optical Transceiver(Grey) & Breakout Model</a></label></li></ul></li><li><input type=checkbox id=section-a55840d746138b3d1fedb81acbccdded class=toggle>
<label for=section-a55840d746138b3d1fedb81acbccdded class="flex justify-between"><a href=/tech-book/docs/programming-tips/>Programming Tips</a></label><ul><li><input type=checkbox id=section-f929f1fe13cb5d6cc96ca3e98f9d9777 class=toggle>
<label for=section-f929f1fe13cb5d6cc96ca3e98f9d9777 class="flex justify-between"><a href=/tech-book/docs/programming-tips/c++/>C++ Tips</a></label></li></ul></li><li><input type=checkbox id=section-b35dbf5ebcd4c19926cf5a9aab6c7655 class=toggle>
<label for=section-b35dbf5ebcd4c19926cf5a9aab6c7655 class="flex justify-between"><a href=/tech-book/docs/systemdesign-tips/>SystemDesign-Tips</a></label><ul><li><input type=checkbox id=section-4a618bc3b0b30107f0cec6d3bd6c025f class=toggle>
<label for=section-4a618bc3b0b30107f0cec6d3bd6c025f class="flex justify-between"><a href=/tech-book/docs/systemdesign-tips/code-deployment-system/>Design A Code-Deployment System</a></label></li><li><input type=checkbox id=section-e600754306aa95ce9c5a72b5efec6d7a class=toggle>
<label for=section-e600754306aa95ce9c5a72b5efec6d7a class="flex justify-between"><a href=/tech-book/docs/systemdesign-tips/stock-broker/>Design A Stock-Broker System</a></label></li><li><input type=checkbox id=section-bfa7a29878f65cfbb179e491c1211fa8 class=toggle>
<label for=section-bfa7a29878f65cfbb179e491c1211fa8 class="flex justify-between"><a href=/tech-book/docs/systemdesign-tips/design-amazon/>Design Amazon</a></label></li><li><input type=checkbox id=section-5456837e25872f6352d861a9b5662cb1 class=toggle>
<label for=section-5456837e25872f6352d861a9b5662cb1 class="flex justify-between"><a href=/tech-book/docs/systemdesign-tips/design-slack/>Design Slack</a></label></li><li><input type=checkbox id=section-5a78d16f54536a400b654f17f917bce1 class=toggle>
<label for=section-5a78d16f54536a400b654f17f917bce1 class="flex justify-between"><a href=/tech-book/docs/systemdesign-tips/google-drive/>Google Drive - Design</a></label></li></ul></li></ul><ul><li><a href=/tech-book/posts/>Blog</a></li><li><a href=https://prasenjitmanna.com/ target=_blank rel=noopener>Prasenjit's Blog</a></li><li><a href=https://prasenjitmanna.com/tech-book/ target=_blank rel=noopener>Prasenjit - Tech Book</a></li><li><a href=https://prasenjitmanna.com/upskills/ target=_blank rel=noopener>Prasenjit - Upskills</a></li></ul></nav><script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script></div></aside><div class=book-page><header class=book-header><div class="flex align-center justify-between"><label for=menu-control><img src=/tech-book/svg/menu.svg class=book-icon alt=Menu>
</label><strong>5. Load Balancing in AI Fabric</strong>
<label for=toc-control><img src=/tech-book/svg/toc.svg class=book-icon alt="Table of Contents"></label></div><aside class="hidden clearfix"><nav id=TableOfContents><ul><li><ul><li><a href=#ai-for-network-engineers-understanding-flow-flowlet-and-packet-based-load-balancing>AI for Network Engineers: Understanding Flow, Flowlet, and Packet-Based Load Balancing</a><ul><li><a href=#rdma-write-operation>RDMA WRITE Operation</a></li><li><a href=#flow-based-load-balancing-with-layer-3-ecmp>Flow-Based Load Balancing with Layer 3 ECMP</a></li><li><a href=#flowlet-based-load-balancing-with-adaptive-routing>Flowlet-Based Load Balancing with Adaptive Routing</a></li><li><a href=#packet-based-load-balancing-with-packet-spraying>Packet-Based Load Balancing with Packet Spraying</a></li><li><a href=#configuring-per-packet-load-balancing-on-cisco-nexus-switches>Configuring Per-Packet Load Balancing on Cisco Nexus Switches </a></li></ul></li></ul></li></ul></nav></aside></header><article class="markdown book-article"><h2 id=ai-for-network-engineers-understanding-flow-flowlet-and-packet-based-load-balancing>AI for Network Engineers: Understanding Flow, Flowlet, and Packet-Based Load Balancing
<a class=anchor href=#ai-for-network-engineers-understanding-flow-flowlet-and-packet-based-load-balancing>#</a></h2><p>Though BGP supports the traditional Flow-based Layer 3 Equal Cost Multi-Pathing (ECMP) traffic load balancing method, it is not the best fit for a RoCEv2-based AI backend network. This is because GPU-to-GPU communication creates massive elephant flows, which RDMA-capable NICs transmit at line rate. These flows can easily cause congestion in the backend network.</p><p>In ECMP, all packets of a single flow follow the same path. If that path becomes congested, ECMP does not adapt or reroute traffic. This leads to uneven bandwidth usage across the network. Some links become overloaded, while others remain idle. In AI workloads, where multiple high-bandwidth flows occur at the same time, this imbalance can degrade performance.</p><p>Deep learning models rely heavily on collective operations like all-reduce, all-gather, and broadcast. These generate dense traffic patterns between GPUs, often at terabit-per-second speeds. If these flows are not evenly distributed, a single congested path can slow down the entire training job.</p><p>This chapter introduces two alternative load balancing methods to traditional Flow-Based with Layer 3 ECMP: 1) Flowlet-Based Load Balancing with Adaptive Routing, and 2) Packet-Based Load Balancing with Packet Spraying. Both aim to improve traffic distribution in RoCEv2-based AI backend networks, where conventional flow-based routing often leads to congestion and underutilized links. These advanced methods are designed to handle the unique traffic patterns of AI workloads more efficiently.</p><h3 id=rdma-write-operation>RDMA WRITE Operation
<a class=anchor href=#rdma-write-operation>#</a></h3><p>Before we explore the load balancing solution, let’s first walk through a simplified example of how the RDMA WRITE memory copy operation works. In Figure 12-1, we have two GPU servers: Host 1 and Host 2, each with one GPU. By this point, the memory has already been allocated and registered, and the Queue Pair (QP) has been created on both sides, so the data transfer can begin.</p><p>On GPU-0 of Host 1, gradients are stored in memory regions highlighted in green, orange, and blue. Each colored section represents a portion of local memory that will be written to GPU-0 on Host 2. To transfer the data, the RDMA NIC on Host 1 splits the write operation into three flowlets (green, orange, and blue). Rather than sending the entire data block as a single continuous stream, each flowlet is treated as a segment of the same RDMA Write operation.</p><h4 id=rdma-write-first>RDMA Write First
<a class=anchor href=#rdma-write-first>#</a></h4><p>The first message carries the RDMA Extended Transport Header (RETH) in its payload. This header tells the receiving RDMA NIC where in the remote memory the incoming data should be written. In our example, data from memory block 1B of GPU-0 on Host 1 is written to memory block 2C of GPU-0 on Host 2.</p><p>The RETH contains the R_Key, which gives permission to write to the remote memory region. It also includes the length of the data being transferred and the virtual address of the target memory location on Host 2.</p><p>The operation code in the InfiniBand Base Transport Header (IBTH) is set to RDMA Write First, indicating that this is the first message in the sequence. The IBTH also describes the Partition Key (interface identifier), the Destination Queue Pair number, and the Packet Sequence Number (PSN) that helps ensure packets are processed in the correct order.</p><p>When this first packet arrives at Host 2, the RDMA NIC uses the Virtual Address information in the RETH  header to write the payload directly into memory block 2C.</p><p><img src=https://prasenjitmanna.com/tech-book/diagrams/ai-ml-dc/load-balancing/image1-1.png alt=img|320x271></p><p><strong>Figure 12-1:</strong> <em>RDMA WRITE First.</em></p><h4 id=rdma-write-middle>RDMA Write Middle
<a class=anchor href=#rdma-write-middle>#</a></h4><p>The second message has the opcode RDMA Write Middle and PSN 2, which tells the receiver that this packet comes after the first one with PSN 1. The payload of this Flowlet is written right after the previous block, into memory block 2D on Host 2. The RDMA NIC ensures that the order is maintained based on PSNs, and it knows exactly where to place the data thanks to the original offset from the first packet.</p><p><img src=https://prasenjitmanna.com/tech-book/diagrams/ai-ml-dc/load-balancing/image1-2.png alt=img|320x271></p><p><strong>Figure 12-2:</strong> <em>RDMA WRITE Middle.</em></p><h4 id=rdma-write-last>RDMA Write Last
<a class=anchor href=#rdma-write-last>#</a></h4><p>The third message has the opcode RDMA Write Last, indicating that this is the final message in the sequence. With PSN 3, it follows directly after PSN 2. The payload in this packet is written into memory block 2E, which comes directly after 2D.</p><p><img src=https://prasenjitmanna.com/tech-book/diagrams/ai-ml-dc/load-balancing/image1-3.png alt=img|320x271></p><p><strong>Figure 12-3:</strong> <em>RDMA WRITE Last.</em></p><p>In a multi-packet RDMA Write operation, each Flowlet represents a continuous block of data being transferred from the source GPU to the destination GPU. Data within packets must arrive in the correct order because only the first packet includes the full addressing information in the RDMA Extended Transport Header (RETH). This header tells the receiver where in memory the data should be written.</p><p>Packets marked as RDMA Write Middle and RDMA Write Last depend on this information and must follow the sequence defined by the Packet Sequence Numbers (PSNs). If packets are delivered out of order, the receiving RDMA NIC cannot process them immediately. Instead, it must hold them in memory and wait for the missing earlier packets to arrive. This buffering increases memory usage and processing overhead. In high-speed environments, this can lead to performance degradation or even packet drops, especially when buffers fill up under heavy load.</p><h3 id=flow-based-load-balancing-with-layer-3-ecmp>Flow-Based Load Balancing with Layer 3 ECMP
<a class=anchor href=#flow-based-load-balancing-with-layer-3-ecmp>#</a></h3><p>Figure 12-4 depicts the problem with flow-based load balancing when used in an AI fabric backend network. In our example, we have four hosts, each equipped with two GPUs: GPU-1 and GPU-2. The RDMA NICs connected to GPU-1s are linked to switch Rail-1, and the RDMA NICs connected to GPU-2s are linked to Rail-2. Traffic between NICs on Rail-1 and Rail-2 is forwarded through either Spine-1 or Spine-2.</p><p>We use a basic data parallelization strategy, where the training dataset is divided into mini-batches and distributed across all eight GPUs. To keep the example simple, Figure 12-4 only shows the all-reduce gradient synchronization flow from the GPU-1s on Hosts 1, 2, and 3 to the GPU-2 on Host 4. In real-world training, a full-mesh all-reduce operation takes place between all GPUs.</p><p>As a starting point, the GPU-1s on the three leftmost hosts begin the RDMA process to copy data from their memory to the memory of GPU-2 on Host 4. These GPU-1s are all connected to Rail-1. Instead of sending one large flow, the RDMA NICs split the data into flowlets, small bursts of data from the larger transfer. These flowlets arrive at the Rail-1 switch, where the 5-tuple L3 ECMP hash algorithm unfortunately selects the same uplink for all three flows. Since the switch cannot forward all the data at wire speed, it stores some of the packets in the buffer, causing congestion. Similar congestion may also occur at the spine switches. As explained earlier in Chapter 12, egress buffer overflow may trigger ECN (Explicit Congestion Notification) and PFC (Priority Flow Control) mechanisms to prevent packet loss. </p><p><img src=https://prasenjitmanna.com/tech-book/diagrams/ai-ml-dc/load-balancing/image1-4.png alt=img|320x271></p><p><strong>Figure 12-4:</strong> <em>Layer 3 Load balancing.</em></p><h3 id=flowlet-based-load-balancing-with-adaptive-routing>Flowlet-Based Load Balancing with Adaptive Routing
<a class=anchor href=#flowlet-based-load-balancing-with-adaptive-routing>#</a></h3><p>Adaptive routing is a dynamic method that actively monitors link utilization and reacts to network congestion in real time. In Figure 12-5, the 5-tuple hash algorithm initially selects the same uplink for all flowlets, just like in the previous example. However, once the utilization of the inter-switch link between Rail-1 and Spine-1 goes over threshold, the adaptive routing mechanism detects the increased load and starts redirecting some of the flowlets to an alternate, less congested path, through Spine-2.</p><p>By distributing the flowlets across multiple paths, adaptive routing helps to reduce buffer buildup and avoid potential packet drops. This not only improves link utilization across the fabric but also helps maintain consistent throughput for time-sensitive operations like RDMA-based gradient synchronization. In AI workloads, where delays or packet loss can slow down or even interrupt training, adaptive routing plays a critical role in maintaining system performance.</p><p><img src=https://prasenjitmanna.com/tech-book/diagrams/ai-ml-dc/load-balancing/image1-5.png alt=img|320x271></p><p><strong>Figure 12-5:</strong> <em>Dynamic Flow Balancing.</em></p><h3 id=packet-based-load-balancing-with-packet-spraying>Packet-Based Load Balancing with Packet Spraying
<a class=anchor href=#packet-based-load-balancing-with-packet-spraying>#</a></h3><p>Packet spraying is a load balancing method where individual packets from the same flow are distributed across multiple equal-cost paths. The idea is to use all available links evenly and reduce the chance of congestion on any single path.</p><p>In a RoCEv2-based AI backend network, however, packet spraying presents serious challenges. RoCEv2 relies on lossless and in-order packet delivery. When packets are sprayed over different paths, they can arrive out of order at the destination. This packet reordering can disrupt RDMA operations and reduce the overall performance of GPU-to-GPU communication.</p><p><img src=https://prasenjitmanna.com/tech-book/diagrams/ai-ml-dc/load-balancing/image1-6.png alt=img|320x271></p><p><strong>Figure 12-6:</strong> <em>Packet Spraying: OpCode: RDMA Write First, Middle, and Last.</em></p><h4 id=rdma-write-only>RDMA Write Only
<a class=anchor href=#rdma-write-only>#</a></h4><p>NVIDIA’s RDMA NICs starting from ConnectX-5 support the RDMA Write Only operation, where a RETH header is included in every packet. Figure 12-7 shows how the RDMA NIC uses the OpCode: RDMA Write Only in the IBTH header for each message. With this OpCode, every message also includes a RETH header, which holds information about the destination memory block reserved for the data carried in the payload. This allows the receiving RDMA NIC to write data directly to the correct memory location without relying on prior messages in the transfer sequence.</p><p>RDMA Write Only, when combined with Packet-Based Load Balancing using Packet Spraying, brings significant benefits. Since each packet is self-contained and includes full memory addressing information, the network fabric can forward individual packets over different paths without worrying about packet ordering or context loss. This enables true flowlet or even per-packet load balancing, which helps spread traffic more evenly across available links, avoids hotspots, and reduces queuing delays. </p><p><img src=https://prasenjitmanna.com/tech-book/diagrams/ai-ml-dc/load-balancing/image1-7.png alt=img|320x271></p><p><strong>Figure 12-7:</strong> <em>Packet Spraying: OpCode: TDMA Write Only.</em></p><h3 id=configuring-per-packet-load-balancing-on-cisco-nexus-switches>Configuring Per-Packet Load Balancing on Cisco Nexus Switches 
<a class=anchor href=#configuring-per-packet-load-balancing-on-cisco-nexus-switches>#</a></h3><p>At the time of writing, Cisco Nexus 9000 Series Cloud Scale switches (9300-FX3, GX, GX2, and HX-TOR), starting from NX-OS Release 10.5(1)F, support Dynamic Load Balancing (DLB)—including flowlet-based and per-packet (packet spraying) load balancing. DLB is supported on Layer 3 physical interfaces in IP-routed and VXLAN fabrics for unicast IPv4 and IPv6 traffic.</p><p>When DLB is enabled, egress QoS and access policies are not applied to flows using DLB. Similarly, TX SPAN configured on an egress interface does not capture DLB traffic. For hardware and software support details, refer to Cisco’s official documentation.</p><p>Example 12-1 shows a basic configuration for enabling per-packet load balancing:</p><pre tabindex=0><code>switch(config)# hardware profile dlb
switch(config-dlb)# dlb-interface Eth1/1
switch(config-dlb)# dlb-interface Eth1/2
switch(config-dlb)# mac-address aa:bb:cc:dd:ee:ff
switch(config-dlb)# mode per-packet
</code></pre><p><strong>Example 12-1:</strong> <em>Configuring Per-Packet Load Balancing Packet Spraying.</em></p><p><strong>Note:</strong> The DLB MAC acts as a virtual next-hop MAC address. It’s not tied to any specific physical interface. This decouples the MAC from the physical path, allowing the switch to choose a different egress port for each packet. The same DLB MAC address must be configured on all participating switches. If you do not specify a DLB MAC, the default DLB MAC 00:CC:CC:CC:CC:CC is applied.</p><p><strong>References:</strong></p><ul><li><a href=https://nwktimes.blogspot.com/2025/04/ai-for-network-engineers-understanding.html>https://nwktimes.blogspot.com/2025/04/ai-for-network-engineers-understanding.html</a></li></ul></article><footer class=book-footer><div class="flex flex-wrap justify-between"><div><a class="flex align-center" href=https://github.com/prmanna/tech-book/commit/643dfc04c216d70bd51b830e71c6edec29e4b9fe title='Last modified by Prasenjit Manna | May 5, 2025' target=_blank rel=noopener><img src=/tech-book/svg/calendar.svg class=book-icon alt>
<span>May 5, 2025</span></a></div></div><script>(function(){function e(e){const t=window.getSelection(),n=document.createRange();n.selectNodeContents(e),t.removeAllRanges(),t.addRange(n)}document.querySelectorAll("pre code").forEach(t=>{t.addEventListener("click",function(){if(window.getSelection().toString())return;e(t.parentElement),navigator.clipboard&&navigator.clipboard.writeText(t.parentElement.textContent)})})})()</script></footer><div class=book-comments></div><label for=menu-control class="hidden book-menu-overlay"></label></div><aside class=book-toc><div class=book-toc-content><nav id=TableOfContents><ul><li><ul><li><a href=#ai-for-network-engineers-understanding-flow-flowlet-and-packet-based-load-balancing>AI for Network Engineers: Understanding Flow, Flowlet, and Packet-Based Load Balancing</a><ul><li><a href=#rdma-write-operation>RDMA WRITE Operation</a></li><li><a href=#flow-based-load-balancing-with-layer-3-ecmp>Flow-Based Load Balancing with Layer 3 ECMP</a></li><li><a href=#flowlet-based-load-balancing-with-adaptive-routing>Flowlet-Based Load Balancing with Adaptive Routing</a></li><li><a href=#packet-based-load-balancing-with-packet-spraying>Packet-Based Load Balancing with Packet Spraying</a></li><li><a href=#configuring-per-packet-load-balancing-on-cisco-nexus-switches>Configuring Per-Packet Load Balancing on Cisco Nexus Switches </a></li></ul></li></ul></li></ul></nav></div></aside></main></body></html>