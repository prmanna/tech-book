<!doctype html><html lang=en-us dir=ltr><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="
  Rail Desings in GPU Fabric
  #

 When building a scalable, resilient GPU network fabric, the design of the rail layer, the portion of the topology that interconnects GPU servers via Top-of-Rack (ToR) switches, plays a critical role. This section explores three different models: Multi-rail-per-switch, Dual-rail-per-switch, and Single-rail-per-switch. All three support dual-NIC-per-GPU designs, allowing each GPU to connect redundantly to two separate switches, thereby removing the Rail switch as a single point of failure."><meta name=theme-color media="(prefers-color-scheme: light)" content="#ffffff"><meta name=theme-color media="(prefers-color-scheme: dark)" content="#343a40"><meta name=color-scheme content="light dark"><meta property="og:url" content="https://prasenjitmanna.com/tech-book/docs/ai-ml-dc/7-rail-desings-in-gpu-fabric/"><meta property="og:site_name" content="Technical Book"><meta property="og:title" content="Load Balancing in AI Fabric"><meta property="og:description" content=" Rail Desings in GPU Fabric # When building a scalable, resilient GPU network fabric, the design of the rail layer, the portion of the topology that interconnects GPU servers via Top-of-Rack (ToR) switches, plays a critical role. This section explores three different models: Multi-rail-per-switch, Dual-rail-per-switch, and Single-rail-per-switch. All three support dual-NIC-per-GPU designs, allowing each GPU to connect redundantly to two separate switches, thereby removing the Rail switch as a single point of failure."><meta property="og:locale" content="en_us"><meta property="og:type" content="article"><meta property="article:section" content="docs"><meta property="article:modified_time" content="2025-05-05T17:43:45+05:30"><title>Load Balancing in AI Fabric | Technical Book</title>
<link rel=manifest href=/tech-book/manifest.json><link rel=icon href=/tech-book/favicon.png><link rel=canonical href=https://prasenjitmanna.com/tech-book/docs/ai-ml-dc/7-rail-desings-in-gpu-fabric/><link rel=stylesheet href=/tech-book/book.min.a61cdb2979f3c2bece54ef69131fba427dd57d55c232d3bb5fdb62ac41aa8354.css integrity="sha256-phzbKXnzwr7OVO9pEx+6Qn3VfVXCMtO7X9tirEGqg1Q=" crossorigin=anonymous><script defer src=/tech-book/fuse.min.js></script><script defer src=/tech-book/en.search.min.d6fefc4754185a3aa4ecc98e3e066e5fab9fd6381dc023666013a968d238cbfd.js integrity="sha256-1v78R1QYWjqk7MmOPgZuX6uf1jgdwCNmYBOpaNI4y/0=" crossorigin=anonymous></script></head><body dir=ltr><input type=checkbox class="hidden toggle" id=menu-control>
<input type=checkbox class="hidden toggle" id=toc-control><main class="container flex"><aside class=book-menu><div class=book-menu-content><nav><h2 class=book-brand><a class="flex align-center" href=/tech-book/><img src=/tech-book/logo.png alt=Logo><span>Technical Book</span></a></h2><div class="book-search hidden"><input type=text id=book-search-input placeholder=Search aria-label=Search maxlength=64 data-hotkeys=s/><div class="book-search-spinner hidden"></div><ul id=book-search-results></ul></div><script>document.querySelector(".book-search").classList.remove("hidden")</script><ul><li><input type=checkbox id=section-99f552133860bc21797a47fe73e93434 class=toggle>
<label for=section-99f552133860bc21797a47fe73e93434 class="flex justify-between"><a href=/tech-book/docs/5g/>5G</a></label><ul><li><input type=checkbox id=section-dfc790b73acb0410a0114547cbf5af32 class=toggle>
<label for=section-dfc790b73acb0410a0114547cbf5af32 class="flex justify-between"><a href=/tech-book/docs/5g/5g-intro/>An Overview of 5G Networking</a></label></li></ul></li><li><input type=checkbox id=section-7c4a3b16aeeb5b7194b232c1eef2f4fb class=toggle>
<label for=section-7c4a3b16aeeb5b7194b232c1eef2f4fb class="flex justify-between"><a href=/tech-book/docs/algorithms/>Algorithms</a></label><ul><li><input type=checkbox id=section-8956d82fbe6869140758f7e8679174bc class=toggle>
<label for=section-8956d82fbe6869140758f7e8679174bc class="flex justify-between"><a href=/tech-book/docs/algorithms/breadth-first-search/>Breadth First Search</a></label></li><li><input type=checkbox id=section-5a049cfad1740f3fd30565524385fa57 class=toggle>
<label for=section-5a049cfad1740f3fd30565524385fa57 class="flex justify-between"><a href=/tech-book/docs/algorithms/depth-first-search/>Depth First Search</a></label></li><li><input type=checkbox id=section-ebc049f26d82165be8c6f1f9e504e799 class=toggle>
<label for=section-ebc049f26d82165be8c6f1f9e504e799 class="flex justify-between"><a href=/tech-book/docs/algorithms/easy/>Easy Complexity</a></label></li><li><input type=checkbox id=section-1071946392bd1f431993e950147fa054 class=toggle>
<label for=section-1071946392bd1f431993e950147fa054 class="flex justify-between"><a href=/tech-book/docs/algorithms/priority-queue-and-heap/>Priority Queue and Heap</a></label></li><li><input type=checkbox id=section-08afbeb294c43ca4908c1c89a4be9d0a class=toggle>
<label for=section-08afbeb294c43ca4908c1c89a4be9d0a class="flex justify-between"><a href=/tech-book/docs/algorithms/two-pointers/>Two Pointers & Sliding Window</a></label></li><li><input type=checkbox id=section-ef36c7c4f7e0dec6525068c3c409100c class=toggle>
<label for=section-ef36c7c4f7e0dec6525068c3c409100c class="flex justify-between"><a href=/tech-book/docs/algorithms/medium/>Medium Complexity</a></label></li></ul></li><li><input type=checkbox id=section-8c7c5c4a8382299873178820b1d91be1 class=toggle checked>
<label for=section-8c7c5c4a8382299873178820b1d91be1 class="flex justify-between"><a href=/tech-book/docs/ai-ml-dc/>Data Center Networking for AI Clusters</a></label><ul><li><input type=checkbox id=section-433ccede4154db01f6c601940d2949e0 class=toggle>
<label for=section-433ccede4154db01f6c601940d2949e0 class="flex justify-between"><a href=/tech-book/docs/ai-ml-dc/1-ai-ml-networking/>AI/ML Networking</a></label></li><li><input type=checkbox id=section-65f71f2455a94ea3d1143666d556b0ed class=toggle>
<label for=section-65f71f2455a94ea3d1143666d556b0ed class="flex justify-between"><a href=/tech-book/docs/ai-ml-dc/2-ai-deep-learning-basics/>Deep Learning Basics | Artificial Neuron</a></label></li><li><input type=checkbox id=section-f11d3aa2e337730e1e3345f8530fe134 class=toggle>
<label for=section-f11d3aa2e337730e1e3345f8530fe134 class="flex justify-between"><a href=/tech-book/docs/ai-ml-dc/3-challenges-in-ai-fabric/>Challenges in AI Fabric Design</a></label></li><li><input type=checkbox id=section-e28420ec7507646128f3695b6f9badbb class=toggle>
<label for=section-e28420ec7507646128f3695b6f9badbb class="flex justify-between"><a href=/tech-book/docs/ai-ml-dc/4-congestion-avoidance-in-ai-fabric/>Congestion Avoidance in AI Fabric</a></label></li><li><input type=checkbox id=section-67bb7cbb1dd95e59f8515201219c090f class=toggle>
<label for=section-67bb7cbb1dd95e59f8515201219c090f class="flex justify-between"><a href=/tech-book/docs/ai-ml-dc/5-load-balancing-in-ai-fabric/>Load Balancing in AI Fabric</a></label></li><li><input type=checkbox id=section-adb8e29f405ea627a0e41d43e94e3453 class=toggle checked>
<label for=section-adb8e29f405ea627a0e41d43e94e3453 class="flex justify-between"><a href=/tech-book/docs/ai-ml-dc/7-rail-desings-in-gpu-fabric/ class=active>Load Balancing in AI Fabric</a></label></li><li><input type=checkbox id=section-5f3e07f6cf7921e5291ff7894e06b19b class=toggle>
<label for=section-5f3e07f6cf7921e5291ff7894e06b19b class="flex justify-between"><a href=/tech-book/docs/ai-ml-dc/6-backend-network-topologies-for-ai-fabric/>Backend Network Topologies for AI Fabrics</a></label></li></ul></li><li><input type=checkbox id=section-3272b2d28b2b247027bf478619ca416f class=toggle>
<label for=section-3272b2d28b2b247027bf478619ca416f class="flex justify-between"><a href=/tech-book/docs/data-center/>Data Center Tips</a></label><ul><li><input type=checkbox id=section-984f932c7aba4f0a1841e8413165c947 class=toggle>
<label for=section-984f932c7aba4f0a1841e8413165c947 class="flex justify-between"><a href=/tech-book/docs/data-center/data-center-ethernet/>Data Center Ethernet</a></label></li><li><input type=checkbox id=section-bc5ac88940153a700e63e3be886c63cc class=toggle>
<label for=section-bc5ac88940153a700e63e3be886c63cc class="flex justify-between"><a href=/tech-book/docs/data-center/data-center-technologies/>Data Center Technologies</a></label></li><li><input type=checkbox id=section-86fde1ddf43700ef8191e11c59a82cf1 class=toggle>
<label for=section-86fde1ddf43700ef8191e11c59a82cf1 class="flex justify-between"><a href=/tech-book/docs/data-center/data-center-network-virtualization/>Network Virtualization in Cloud Data Centers</a></label></li></ul></li><li><input type=checkbox id=section-ddf784688e0c6d5abb681d2c57851559 class=toggle>
<label for=section-ddf784688e0c6d5abb681d2c57851559 class="flex justify-between"><a href=/tech-book/docs/manageability/>Manageability</a></label><ul><li><input type=checkbox id=section-33ac730897af6feca81c1fdb7869c57e class=toggle>
<label for=section-33ac730897af6feca81c1fdb7869c57e class="flex justify-between"><a href=/tech-book/docs/manageability/why-grpc-on-http2/>gRPC on HTTP/2</a></label></li></ul></li><li><input type=checkbox id=section-c14ae944424668ef125e10cd791a3d3d class=toggle>
<label for=section-c14ae944424668ef125e10cd791a3d3d class="flex justify-between"><a href=/tech-book/docs/networking-tips/>Networking Tips</a></label><ul><li><input type=checkbox id=section-78fdf21c03c55935d3146441b06faf3e class=toggle>
<label for=section-78fdf21c03c55935d3146441b06faf3e class="flex justify-between"><a href=/tech-book/docs/networking-tips/dns/>DNS Overview</a></label></li><li><input type=checkbox id=section-bbcb027a658dc7a2333d59078ee507f9 class=toggle>
<label for=section-bbcb027a658dc7a2333d59078ee507f9 class="flex justify-between"><a href=/tech-book/docs/networking-tips/ecmp/>ECMP Load Balancing</a></label></li><li><input type=checkbox id=section-3b39b86f18b3451e5b8a1b81c369549c class=toggle>
<label for=section-3b39b86f18b3451e5b8a1b81c369549c class="flex justify-between"><a href=/tech-book/docs/networking-tips/ip-fragmentation/>IP Fragmentation - IPv4 & IPv6</a></label></li><li><input type=checkbox id=section-c6d06c54cc91b0bc3f948d33b437fa8b class=toggle>
<label for=section-c6d06c54cc91b0bc3f948d33b437fa8b class="flex justify-between"><a href=/tech-book/docs/networking-tips/ip-tos-dscp/>IP Precedence And TOS | DSCP</a></label></li><li><input type=checkbox id=section-5f3260c76dd37177e3f89057bfe520ae class=toggle>
<label for=section-5f3260c76dd37177e3f89057bfe520ae class="flex justify-between"><a href=/tech-book/docs/networking-tips/traceroute/>Linux traceroute tool</a></label></li><li><input type=checkbox id=section-a26cc3fafb36cbc55527adf39ec83849 class=toggle>
<label for=section-a26cc3fafb36cbc55527adf39ec83849 class="flex justify-between"><a href=/tech-book/docs/networking-tips/mlag/>Multi Chassis Link Aggregation Basics</a></label></li><li><input type=checkbox id=section-36409a0abcb2d4d4baf2e0b682d1a5dd class=toggle>
<label for=section-36409a0abcb2d4d4baf2e0b682d1a5dd class="flex justify-between"><a href=/tech-book/docs/networking-tips/qos/>QoS</a></label></li><li><input type=checkbox id=section-db41e3547d316b01acf9a0ce9c04ef34 class=toggle>
<label for=section-db41e3547d316b01acf9a0ce9c04ef34 class="flex justify-between"><a href=/tech-book/docs/networking-tips/spine-leaf-arch/>Spine-leaf Architecture Basics</a></label></li><li><input type=checkbox id=section-0eb0d409074a76b8cb02624655e2434d class=toggle>
<label for=section-0eb0d409074a76b8cb02624655e2434d class="flex justify-between"><a href=/tech-book/docs/networking-tips/tcp-congestion/>TCP Congestion Control</a></label></li><li><input type=checkbox id=section-3d1710947b3c5be1a1cc33d88fcc6f54 class=toggle>
<label for=section-3d1710947b3c5be1a1cc33d88fcc6f54 class="flex justify-between"><a href=/tech-book/docs/networking-tips/tcp-data-transfer/>TCP Data Transfer</a></label></li></ul></li><li><input type=checkbox id=section-f0a392f2f083f28a4991336773716a63 class=toggle>
<label for=section-f0a392f2f083f28a4991336773716a63 class="flex justify-between"><a href=/tech-book/docs/optical-knowledge/>Optical Knowledge</a></label><ul><li><input type=checkbox id=section-18261b95a92d4fa86116243edca4e9fb class=toggle>
<label for=section-18261b95a92d4fa86116243edca4e9fb class="flex justify-between"><a href=/tech-book/docs/optical-knowledge/optical-breakout/>Optical Transceiver(Grey) & Breakout Model</a></label></li></ul></li><li><input type=checkbox id=section-a55840d746138b3d1fedb81acbccdded class=toggle>
<label for=section-a55840d746138b3d1fedb81acbccdded class="flex justify-between"><a href=/tech-book/docs/programming-tips/>Programming Tips</a></label><ul><li><input type=checkbox id=section-f929f1fe13cb5d6cc96ca3e98f9d9777 class=toggle>
<label for=section-f929f1fe13cb5d6cc96ca3e98f9d9777 class="flex justify-between"><a href=/tech-book/docs/programming-tips/c++/>C++ Tips</a></label></li></ul></li><li><input type=checkbox id=section-b35dbf5ebcd4c19926cf5a9aab6c7655 class=toggle>
<label for=section-b35dbf5ebcd4c19926cf5a9aab6c7655 class="flex justify-between"><a href=/tech-book/docs/systemdesign-tips/>SystemDesign-Tips</a></label><ul><li><input type=checkbox id=section-4a618bc3b0b30107f0cec6d3bd6c025f class=toggle>
<label for=section-4a618bc3b0b30107f0cec6d3bd6c025f class="flex justify-between"><a href=/tech-book/docs/systemdesign-tips/code-deployment-system/>Design A Code-Deployment System</a></label></li><li><input type=checkbox id=section-e600754306aa95ce9c5a72b5efec6d7a class=toggle>
<label for=section-e600754306aa95ce9c5a72b5efec6d7a class="flex justify-between"><a href=/tech-book/docs/systemdesign-tips/stock-broker/>Design A Stock-Broker System</a></label></li><li><input type=checkbox id=section-bfa7a29878f65cfbb179e491c1211fa8 class=toggle>
<label for=section-bfa7a29878f65cfbb179e491c1211fa8 class="flex justify-between"><a href=/tech-book/docs/systemdesign-tips/design-amazon/>Design Amazon</a></label></li><li><input type=checkbox id=section-5456837e25872f6352d861a9b5662cb1 class=toggle>
<label for=section-5456837e25872f6352d861a9b5662cb1 class="flex justify-between"><a href=/tech-book/docs/systemdesign-tips/design-slack/>Design Slack</a></label></li><li><input type=checkbox id=section-5a78d16f54536a400b654f17f917bce1 class=toggle>
<label for=section-5a78d16f54536a400b654f17f917bce1 class="flex justify-between"><a href=/tech-book/docs/systemdesign-tips/google-drive/>Google Drive - Design</a></label></li></ul></li></ul><ul><li><a href=/tech-book/posts/>Blog</a></li><li><a href=https://prasenjitmanna.com/ target=_blank rel=noopener>Prasenjit's Blog</a></li><li><a href=https://prasenjitmanna.com/tech-book/ target=_blank rel=noopener>Prasenjit - Tech Book</a></li><li><a href=https://prasenjitmanna.com/upskills/ target=_blank rel=noopener>Prasenjit - Upskills</a></li></ul></nav><script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script></div></aside><div class=book-page><header class=book-header><div class="flex align-center justify-between"><label for=menu-control><img src=/tech-book/svg/menu.svg class=book-icon alt=Menu>
</label><strong>Load Balancing in AI Fabric</strong>
<label for=toc-control><img src=/tech-book/svg/toc.svg class=book-icon alt="Table of Contents"></label></div><aside class="hidden clearfix"><nav id=TableOfContents><ul><li><ul><li><ul><li><a href=#rail-desings-in-gpu-fabric>Rail Desings in GPU Fabric</a></li><li><a href=#multi-rail-per-switch>Multi-Rail-per-Switch</a><ul><li><a href=#dual-rail-per-switch>Dual-Rail-per-Switch</a></li><li><a href=#single-rail-per-switch>Single-Rail-per-Switch</a></li></ul></li><li><a href=#ai-fabric-architecture-conclusion>AI Fabric Architecture Conclusion</a><ul><li><a href=#segment-gpu-io-topology-and-rail-switch-fabric-profile>Segment: GPU I/O Topology and Rail Switch Fabric Profile</a></li><li><a href=#pod-spine-switch-profile>Pod: Spine Switch Profile:</a></li><li><a href=#multi-pod-super-spine-switch-profile>Multi-Pod: Super Spine Switch Profile</a></li><li><a href=#global-ai-fabric-profile>Global AI Fabric Profile</a></li></ul></li></ul></li></ul></li></ul></nav></aside></header><article class="markdown book-article"><h3 id=rail-desings-in-gpu-fabric>Rail Desings in GPU Fabric
<a class=anchor href=#rail-desings-in-gpu-fabric>#</a></h3><p> When building a scalable, resilient GPU network fabric, the design of the rail layer, the portion of the topology that interconnects GPU servers via Top-of-Rack (ToR) switches, plays a critical role. This section explores three different models: Multi-rail-per-switch, Dual-rail-per-switch, and Single-rail-per-switch. All three support dual-NIC-per-GPU designs, allowing each GPU to connect redundantly to two separate switches, thereby removing the Rail switch as a single point of failure.</p><h3 id=multi-rail-per-switch>Multi-Rail-per-Switch
<a class=anchor href=#multi-rail-per-switch>#</a></h3><p>In this model, multiple small subnets and VLANs are configured per switch, with each logical rail mapped to a subset of physical interfaces. For example, a single 48-port switch might host four or eight logical rails using distinct Layer 2 and Layer 3 domains. Because all logical rails share the same physical device, isolation is logical. As a result, a hardware or software failure in the switch can impact all rails and their associated GPUs, creating a large failure domain.</p><p>This model is not part of NVIDIA’s validated Scalable Unit (SU) architecture but may suit test environments, development clusters, or small-scale GPU fabrics where hardware cost efficiency is a higher priority than strict fault isolation. From a CapEx perspective, multi-rail-per-switch is the most economical, requiring fewer switches. </p><p>Figure 13-10 illustrates the multi-rail-per-switch architecture, where each rail is implemented as a separate VLAN-subnet pair mapped to a subset of switch ports. In the figure, interfaces 1–4 are assigned to subnet 10.0.1.0/28 and VLAN 101, while interfaces 5–8 are mapped to subnet 10.0.2.0/28 and VLAN 102. Each VLAN maintains its own MAC address table, learning GPU NIC MACs through ingress traffic. Although not shown in the figure, the Rail switch acts as the default gateway for all eight VLANs.</p><p>The figure also illustrates the BGP process when a Clos architecture with a spine layer is used to connect rail switches. All directly connected subnets are installed into the local Routing Information Base (RIB) as connected routes. These routes are then imported into the BGP Loc-RIB. Next, the routes pass through the BGP output policy engine, where they are aggregated into a single summary route: 10.0.1.0/24. This aggregate is placed into the BGP Adj-RIB-Out. When the BGP Update message is sent to a peer, the NEXT_HOP attribute is set accordingly.</p><p><a href=https://blogger.googleusercontent.com/img/a/AVvXsEgt5HP-lbtT7VxqTjGqASRlQmEg81yEfjE-3MGcZs-YRgO6OLY1C36N8qG3m-Q7hLPBagi9x_OKuwyP0_j6LTHY0qnYD3TLSaFKqfdRBD-jdBIU50_DAt368qhOBGFUs6G66uu6K9bw3n_FBOnDYR1kZ7P6KDOtNLd4EVBa0t-A06BFMZwmHccC31bcQUc><img src="https://blogger.googleusercontent.com/img/a/AVvXsEgt5HP-lbtT7VxqTjGqASRlQmEg81yEfjE-3MGcZs-YRgO6OLY1C36N8qG3m-Q7hLPBagi9x_OKuwyP0_j6LTHY0qnYD3TLSaFKqfdRBD-jdBIU50_DAt368qhOBGFUs6G66uu6K9bw3n_FBOnDYR1kZ7P6KDOtNLd4EVBa0t-A06BFMZwmHccC31bcQUc=w640-h362" alt></a></p><p><strong>Figure 13-10:</strong> <em>Multi-Rail per Switch.</em></p><h4 id=dual-rail-per-switch>Dual-Rail-per-Switch
<a class=anchor href=#dual-rail-per-switch>#</a></h4><p>While dual-rail-per-switch improves manageability and is easier to scale, it shares the same limitation: both logical rails reside within a single physical switch, so the failure domain remains large. A single switch failure or misconfiguration affects both rails and all associated GPUs. </p><p>This design resembles the dual-rail concept used in scalable AI clusters, but NVIDIA’s SU approach calls for two separate physical switches per rail, which provides full physical isolation. Dual-rail-per-switch hits a middle ground in terms of CapEx and OpEx: fewer switches are required than in the single-rail model, and operational complexity is reduced compared to multi-rail. It’s often a good choice for intermediate-scale environments where some fault tolerance and cost control must be balanced. </p><p>Figure 13-11 illustrates a dual-rail-per-switch design, where the switch interfaces are divided evenly between two separate rails. Rail 1 uses interfaces 1 through 16 and is assigned to subnet 10.0.1.0/25 (VLAN 101). Rail 2 uses interfaces 17 through 32 and is assigned to subnet 10.0.128.0/25 (VLAN 102). Each VLAN has its own MAC address table, and the rail switch serves as the default gateway for both. The individual /25 subnets are redistributed into the BGP process and summarized as 10.0.1.0/24 for advertisement toward the spine layer.</p><p><a href=https://blogger.googleusercontent.com/img/a/AVvXsEgsbaYkM3oTqnmRJnnRrQxNgxx8pAh0d1ljz5J_ttGJuXshtEhb7iP1cZc3__oel5lX9zdNf5VEleMAVHfuhlhktUYOP0MdK1JYuvEtwG4nw7cTM773evCesjDUMp5anCRoz_O3ac4YGIy17k1rLcIgEssAAsbbjX66j_WkgedsN1l3iBL8Y0gdRISn-20><img src="https://blogger.googleusercontent.com/img/a/AVvXsEgsbaYkM3oTqnmRJnnRrQxNgxx8pAh0d1ljz5J_ttGJuXshtEhb7iP1cZc3__oel5lX9zdNf5VEleMAVHfuhlhktUYOP0MdK1JYuvEtwG4nw7cTM773evCesjDUMp5anCRoz_O3ac4YGIy17k1rLcIgEssAAsbbjX66j_WkgedsN1l3iBL8Y0gdRISn-20=w640-h362" alt></a></p><p><strong>Figure 13-11:</strong> <em>Dual-Rail Switch.</em></p><h4 id=single-rail-per-switch>Single-Rail-per-Switch
<a class=anchor href=#single-rail-per-switch>#</a></h4><p>This model offers the highest level of physical isolation. Each switch forms a single rail, serving its connected GPU servers through one subnet and one VLAN. No logical separation is needed, as each rail is entirely independent in hardware. As a result, a switch failure affects only the GPU servers attached to that specific rail, yielding a small, predictable failure domain.</p><p>The design closely aligns with NVIDIA’s Scalable Unit (SU) architecture, in which each rack or rack group includes its own rail switch, and horizontal scaling is achieved by repeating modular, self-contained units.</p><p>While this model demands the highest CapEx, due to the one-to-one mapping between switches and rails, it offers major operational advantages. Configuration is simpler, troubleshooting is faster, and the risk of cascading faults is minimized. There is no need for route summarization, or custom BGP redistribution logic. Over time, these benefits help drive down OpEx, particularly in large-scale or mission-critical GPU clusters.</p><p>To ensure optimal hardware utilization, it is important to align the number of GPU servers per rack with the switch’s port capacity. Otherwise, underutilized ports can lead to inefficiencies in infrastructure cost and resource planning.</p><p>Figure 13-12 illustrates a simplified single-rail-per-switch topology. All interfaces from 1 to 32 operate within a single rail, configured with subnet 10.0.1.0/24 and VLAN 101. The rail switch serves as the default gateway, and because the full /24 subnet is used without subnetting, route summarization is not needed.</p><p><a href=https://blogger.googleusercontent.com/img/a/AVvXsEifLMfdKtnlaR9yGe193tZ430CEYQozEp4VRnuJskOya6MVW5_OUeg_tUYw3yDooInpngBZV6H4fL3tcFz-xpa-umdUSB79JYqShgjx5YO0RE8-vVX8GcBs7IM4fob9pv6KXbSlKO1LjFYuMb3HN2ipeOo_9gJmFZ8y1BZl8UEId5JPNOtAOyXq_UnTk0w><img src="https://blogger.googleusercontent.com/img/a/AVvXsEifLMfdKtnlaR9yGe193tZ430CEYQozEp4VRnuJskOya6MVW5_OUeg_tUYw3yDooInpngBZV6H4fL3tcFz-xpa-umdUSB79JYqShgjx5YO0RE8-vVX8GcBs7IM4fob9pv6KXbSlKO1LjFYuMb3HN2ipeOo_9gJmFZ8y1BZl8UEId5JPNOtAOyXq_UnTk0w=w640-h360" alt></a></p><p><strong>Figure 13-12:</strong> <em>Single-Rail Switch.</em></p><h3 id=ai-fabric-architecture-conclusion>AI Fabric Architecture Conclusion
<a class=anchor href=#ai-fabric-architecture-conclusion>#</a></h3><p>Figure 13-13 illustrates one way to describe the overall architecture of an AI Fabric. It is divided into three domains. The first domain, called the Segment, includes GPU hosts and Rail switches. The second domain, the Pod, aggregates multiple segments using Spine switches. In cases where NCCL builds a topology where cross-rail inter-host traffic is first copied to the local GPU memory (located on the destination rail) and then sent over the GPU NIC to the remote GPU via the correct Rail switch, a Pod architecture with Spine switches may not be necessary. The third domain, multi-Pod, interconnects multiple pods using Super Spine switches, enabling large-scale AI Fabric deployments. Figure 13-10 also depicts global settings and properties shared across the AI Fabric backend network.</p><h4 id=segment-gpu-io-topology-and-rail-switch-fabric-profile>Segment: GPU I/O Topology and Rail Switch Fabric Profile
<a class=anchor href=#segment-gpu-io-topology-and-rail-switch-fabric-profile>#</a></h4><p>GPU I/O Topology: Each GPU connects to the network through a NIC. You can either dedicate a NIC to each GPU or share one NIC among multiple GPUs. NICs may have single, dual, or quad ports and support speeds such as 100, 200, or 400 Gbps. The interconnect type can be InfiniBand, RoCEv2, or NVLink. A segment typically includes multiple hosts.</p><p>Rail Switch Fabric Profile: Rail switches connect directly to GPU hosts. Each rail handles a group of NIC ports. You can map rails one-to-one to switches for physical isolation or map multiple rails per switch for logical isolation. In the latter case, two or more rails can be mapped per switch depending on performance and capacity requirements. Rail switches are responsible for ingress packet classification and for mapping RoCEv2 traffic to the correct queues. </p><h4 id=pod-spine-switch-profile>Pod: Spine Switch Profile:
<a class=anchor href=#pod-spine-switch-profile>#</a></h4><p>Spine switches aggregate multiple Rail switches, forming a Pod that consists of n segments. Spine switches enable cross-rail communication between GPUs. They use high-density, high-speed ports. When the Spine layer is used, the result is a 2-tier, 3-stage architecture.</p><h4 id=multi-pod-super-spine-switch-profile>Multi-Pod: Super Spine Switch Profile
<a class=anchor href=#multi-pod-super-spine-switch-profile>#</a></h4><p>Super Spine switches provide inter-Pod connectivity. They are built with very high port density to support all connected Spine switches. When the Super Spine layer is used, the architecture becomes a 3-tier, 5-stage fabric.</p><h4 id=global-ai-fabric-profile>Global AI Fabric Profile
<a class=anchor href=#global-ai-fabric-profile>#</a></h4><p>All layers are governed by the Global AI Fabric Profile. This profile defines the control plane (eBGP, iBGP, BGP EVPN), the data plane (Ethernet, VXLAN), Layer 3 ECMP strategies (flow-based, flowlet-based, or per-packet), congestion control mechanisms (ECN marking, PFC), inter-switch link monitoring (BFD), and global MTU settings.</p><p><a href=https://blogger.googleusercontent.com/img/a/AVvXsEj7_00ITgHG7QjwO09WynARjv1wY2bthWcXn1uwAi46ZeeYa9vxEx-GnNY4qTuJv4bjw_iFvRhP2CZ63cWrPRhCgoD1nkfohECdjyiVIt5wt1I55EgrSfJ-izw9Pv2tukzMTpZiuBXHJkETio5z57vxY-ghqq5YdPKriUp_bodF46Mg4Lv4BPPLYDvq6wM><img src="https://blogger.googleusercontent.com/img/a/AVvXsEj7_00ITgHG7QjwO09WynARjv1wY2bthWcXn1uwAi46ZeeYa9vxEx-GnNY4qTuJv4bjw_iFvRhP2CZ63cWrPRhCgoD1nkfohECdjyiVIt5wt1I55EgrSfJ-izw9Pv2tukzMTpZiuBXHJkETio5z57vxY-ghqq5YdPKriUp_bodF46Mg4Lv4BPPLYDvq6wM=w640-h362" alt></a></p><p><strong>Figure 13-13:</strong> <em>AI fabric Architecture Description.</em></p><p><strong>References:</strong>
*</p></article><footer class=book-footer><div class="flex flex-wrap justify-between"><div><a class="flex align-center" href=https://github.com/prmanna/tech-book/commit/2ad9d125fc542fd3713a54b063c2d309190004bb title='Last modified by Prasenjit Manna | May 5, 2025' target=_blank rel=noopener><img src=/tech-book/svg/calendar.svg class=book-icon alt>
<span>May 5, 2025</span></a></div></div><script>(function(){function e(e){const t=window.getSelection(),n=document.createRange();n.selectNodeContents(e),t.removeAllRanges(),t.addRange(n)}document.querySelectorAll("pre code").forEach(t=>{t.addEventListener("click",function(){if(window.getSelection().toString())return;e(t.parentElement),navigator.clipboard&&navigator.clipboard.writeText(t.parentElement.textContent)})})})()</script></footer><div class=book-comments></div><label for=menu-control class="hidden book-menu-overlay"></label></div><aside class=book-toc><div class=book-toc-content><nav id=TableOfContents><ul><li><ul><li><ul><li><a href=#rail-desings-in-gpu-fabric>Rail Desings in GPU Fabric</a></li><li><a href=#multi-rail-per-switch>Multi-Rail-per-Switch</a><ul><li><a href=#dual-rail-per-switch>Dual-Rail-per-Switch</a></li><li><a href=#single-rail-per-switch>Single-Rail-per-Switch</a></li></ul></li><li><a href=#ai-fabric-architecture-conclusion>AI Fabric Architecture Conclusion</a><ul><li><a href=#segment-gpu-io-topology-and-rail-switch-fabric-profile>Segment: GPU I/O Topology and Rail Switch Fabric Profile</a></li><li><a href=#pod-spine-switch-profile>Pod: Spine Switch Profile:</a></li><li><a href=#multi-pod-super-spine-switch-profile>Multi-Pod: Super Spine Switch Profile</a></li><li><a href=#global-ai-fabric-profile>Global AI Fabric Profile</a></li></ul></li></ul></li></ul></li></ul></nav></div></aside></main></body></html>